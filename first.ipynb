{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn,Tensor\n",
    "from typing import Union, Tuple, List, Iterable, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf_data = pd.read_csv('./msf_baby_bonus.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_data = pd.read_csv('./aprilfinal.csv')\n",
    "test2_data['original']  =test2_data['original'].apply(lambda x : x.replace('\\n',''))\n",
    "test2_data['reframed']  =test2_data['reframed'].apply(lambda x : x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json') as f:\n",
    "    generated_ques = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_answers.txt', 'r') as f:\n",
    "    test_answers = f.readlines()\n",
    "    test_answers = list(map(lambda x : x.replace('\\n',''),test_answers))\n",
    "    test_answers = list(filter(lambda x : len(x) > 0 , test_answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_questions.txt', 'r') as f:\n",
    "    test_questions = f.readlines()\n",
    "    test_questions  = list(map(lambda x : x.replace('\\n',''),test_questions))\n",
    "    test_questions  = list(filter(lambda x : len(x) > 0 , test_questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'r', encoding=\"utf8\") as f:\n",
    "    answers = f.readlines()\n",
    "    answers  = list(map(lambda x : x.replace('\\n',''),answers))\n",
    "    answers  = list(filter(lambda x : len(x) > 0 , answers))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_answers = msf_data[2].tolist()\n",
    "csv_answers = list(map(lambda x : x.replace('\\n', '').strip(),csv_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_questions = msf_data[1].tolist()\n",
    "csv_questions = list(map(lambda x : x.replace('\\n', '').strip(),csv_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    questions = []\n",
    "    labels = []\n",
    "    for q,a in zip(csv_questions , csv_answers):\n",
    "        if(a not in answers):\n",
    "            continue\n",
    "        \n",
    "        questions.append(q)\n",
    "        labels.append(answers.index(a))\n",
    "    return questions , labels\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions , labels = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts')\n",
    "sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from modelInterface import modelInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Did not find and preexisting of baby_bonus so you must provide faq_data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5d5b231c83f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelInter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelInterface\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaq_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"baby_bonus\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\scripts\\modelInterface.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, faq_name, faq_data, model_path)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfaq_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"Did not find and preexisting of {} so you must provide faq_data\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaq_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_faq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaq_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Did not find and preexisting of baby_bonus so you must provide faq_data"
     ]
    }
   ],
   "source": [
    "modelInter = modelInterface(faq_name=\"baby_bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions_labels_dict  = {}\n",
    "data_questions_label_dict = {}\n",
    "for q,l in zip(questions, labels):\n",
    "    data_questions_label_dict[q] = l\n",
    "    gens = generated_ques[q]\n",
    "  #  gens += aug(q,10)\n",
    "    for gen in gens:\n",
    "        data_questions_label_dict[gen] = l\n",
    "for q,l in zip(test_questions, test_answers):\n",
    "    test_questions_labels_dict[q] = l\n",
    "    \n",
    "answer_to_label = {ans: i for i,ans in enumerate(answers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {'question_to_label': data_questions_label_dict , 'answer_to_label': answer_to_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3134"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_questions_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./scripts\\utils.py:111: UserWarning: k is greater than than number of generated ques\n",
      "  warnings.warn('k is greater than than number of generated ques')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7c0b3439e049bc99c5217e03bc0e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a2a0188d974850abb48236ed8d0cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1044.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0056, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0555, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0094, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2182, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0774, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0691, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4614, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2129, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4021, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2515, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2384, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2252, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9226, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1251, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3954, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0115, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1159, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1295, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6568, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2347, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5619, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0799, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1934, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2644, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2459, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2503, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2301, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1456, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1408, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5432, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0736, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4499, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6981, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5878, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9376, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1158, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1275, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1091, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5630, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2229, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2544, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2471, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1456, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0049, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4854, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8435, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3368, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9140, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3316, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4499, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5975, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8405, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2747, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0327, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0273, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2119, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1361, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2629, grad_fn=<MeanBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-da802b575491>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelInter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/checkpoints/model5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\scripts\\modelInterface.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model_save_path, data)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         )\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, fp16, fp16_opt_level, local_rank)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                     \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfp16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\losses\\BatchHardTripletLoss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sentence_features, labels)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mreps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence_embedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_embedding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mBatchHardTripletLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_hard_triplet_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriplet_margin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\losses\\BatchHardTripletLoss.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mreps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence_embedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_embedding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mBatchHardTripletLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_hard_triplet_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriplet_margin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\models\\RoBERTa.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;34m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutput_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mcls_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# CLS token is first token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m         )\n\u001b[0;32m    736\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             layer_outputs = layer_module(\n\u001b[1;32m--> 408\u001b[1;33m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m             )\n\u001b[0;32m    410\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     ):\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mself_attention_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add self attentions if we output attention weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    313\u001b[0m     ):\n\u001b[0;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         )\n\u001b[0;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     ):\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mmixed_query_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelInter.train(\"/checkpoints/model5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 label present in answer but not in question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./scripts\\modelInterface.py:327: UserWarning: some labels in answers are not present in questions , you might not have labels in Sync\n",
      "  warnings.warn('some labels in answers are not present in questions , you might not have labels in Sync')\n"
     ]
    }
   ],
   "source": [
    "modelInter.fit_FAQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelInter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-059a18759218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelInter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_FAQ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_questions_label_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer_to_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'modelInter' is not defined"
     ]
    }
   ],
   "source": [
    "modelInter.fit_FAQ(data_questions_label_dict, answer_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5702707767486572\n",
      "Answering When will CDA bank record be updated to show my savings deposited recently?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Child Development Account (CDA) banks will update MSF with your deposit information on a weekly basis. You should be able to view your CDA savings by the following Tuesday on the Baby Bonus Online portal. Alternatively, you can use your bank’s internet banking services to check your savings in the CDA.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInter.answer_question('what bank should I use ?', K = 1, cutoff = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f8843d674b4be59e9088fc6a840ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8714e3ff2d904f62ba7e9c1461ad8e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=293.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([198, 198, 198, 198, 198, 198, 198, 198, 184, 184, 184, 184, 184, 184,\n",
      "        184, 184,  48,  48,  48,  48,  48,  48,  48,  48, 206, 206, 206, 206,\n",
      "        206, 206, 206, 206,  97,  97,  97,  97,  97,  97,  97,  97, 107, 107,\n",
      "        107, 107, 107, 107, 107, 107,  33,  33,  33,  33,  33,  33,  33,  33,\n",
      "        124, 124, 124, 124, 124, 124, 124, 124], dtype=torch.int32)\n",
      "tensor(1.1054, grad_fn=<MeanBackward0>)\n",
      "tensor([175, 175, 175, 175, 175, 175, 175, 175,  39,  39,  39,  39,  39,  39,\n",
      "         39,  39, 255, 255, 255, 255, 255, 255, 255, 255,  78,  78,  78,  78,\n",
      "         78,  78,  78,  78,  88,  88,  88,  88,  88,  88,  88,  88, 258, 258,\n",
      "        258, 258, 258, 258, 258, 258,  64,  64,  64,  64,  64,  64,  64,  64,\n",
      "         21,  21,  21,  21,  21,  21,  21,  21], dtype=torch.int32)\n",
      "tensor(0.4469, grad_fn=<MeanBackward0>)\n",
      "tensor([156, 156, 156, 156, 156, 156, 156, 156, 224, 224, 224, 224, 224, 224,\n",
      "        224, 224, 154, 154, 154, 154, 154, 154, 154, 154, 178, 178, 178, 178,\n",
      "        178, 178, 178, 178,  69,  69,  69,  69,  69,  69,  69,  69,  20,  20,\n",
      "         20,  20,  20,  20,  20,  20, 119, 119, 119, 119, 119, 119, 119, 119,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196], dtype=torch.int32)\n",
      "tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor([132, 132, 132, 132, 132, 132, 132, 132, 279, 279, 279, 279, 279, 279,\n",
      "        279, 279, 247, 247, 247, 247, 247, 247, 247, 247, 119, 119, 119, 119,\n",
      "        119, 119, 119, 119, 240, 240, 240, 240, 240, 240, 240, 240, 222, 222,\n",
      "        222, 222, 222, 222, 222, 222, 176, 176, 176, 176, 176, 176, 176, 176,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133], dtype=torch.int32)\n",
      "tensor(0.3487, grad_fn=<MeanBackward0>)\n",
      "tensor([ 89,  89,  89,  89,  89,  89,  89,  89, 203, 203, 203, 203, 203, 203,\n",
      "        203, 203,  50,  50,  50,  50,  50,  50,  50,  50, 238, 238, 238, 238,\n",
      "        238, 238, 238, 238, 239, 239, 239, 239, 239, 239, 239, 239,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,  47,  47,  47,  47,  47,  47,  47,  47,\n",
      "        170, 170, 170, 170, 170, 170, 170, 170], dtype=torch.int32)\n",
      "tensor(1.1174, grad_fn=<MeanBackward0>)\n",
      "tensor([175, 175, 175, 175, 175, 175, 175, 175, 278, 278, 278, 278, 278, 278,\n",
      "        278, 278,   9,   9,   9,   9,   9,   9,   9,   9,  39,  39,  39,  39,\n",
      "         39,  39,  39,  39, 225, 225, 225, 225, 225, 225, 225, 225,  74,  74,\n",
      "         74,  74,  74,  74,  74,  74, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "         67,  67,  67,  67,  67,  67,  67,  67], dtype=torch.int32)\n",
      "tensor(0.2026, grad_fn=<MeanBackward0>)\n",
      "tensor([ 50,  50,  50,  50,  50,  50,  50,  50,  85,  85,  85,  85,  85,  85,\n",
      "         85,  85, 226, 226, 226, 226, 226, 226, 226, 226, 209, 209, 209, 209,\n",
      "        209, 209, 209, 209, 138, 138, 138, 138, 138, 138, 138, 138, 136, 136,\n",
      "        136, 136, 136, 136, 136, 136, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127], dtype=torch.int32)\n",
      "tensor(0.7514, grad_fn=<MeanBackward0>)\n",
      "tensor([  3,   3,   3,   3,   3,   3,   3,   3, 233, 233, 233, 233, 233, 233,\n",
      "        233, 233, 158, 158, 158, 158, 158, 158, 158, 158, 198, 198, 198, 198,\n",
      "        198, 198, 198, 198,  68,  68,  68,  68,  68,  68,  68,  68,  14,  14,\n",
      "         14,  14,  14,  14,  14,  14, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        256, 256, 256, 256, 256, 256, 256, 256], dtype=torch.int32)\n",
      "tensor(0.4718, grad_fn=<MeanBackward0>)\n",
      "tensor([ 96,  96,  96,  96,  96,  96,  96,  96, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149,  90,  90,  90,  90,  90,  90,  90,  90,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70, 277, 277, 277, 277, 277, 277, 277, 277, 135, 135,\n",
      "        135, 135, 135, 135, 135, 135, 189, 189, 189, 189, 189, 189, 189, 189,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128], dtype=torch.int32)\n",
      "tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "tensor([285, 285, 285, 285, 285, 285, 285, 285,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  44,  44,  44,  44,  44,  44,  44,  44,  34,  34,  34,  34,\n",
      "         34,  34,  34,  34, 107, 107, 107, 107, 107, 107, 107, 107, 133, 133,\n",
      "        133, 133, 133, 133, 133, 133, 249, 249, 249, 249, 249, 249, 249, 249,\n",
      "        249, 249, 249, 249, 249, 249, 249, 249], dtype=torch.int32)\n",
      "tensor(0.5593, grad_fn=<MeanBackward0>)\n",
      "tensor([248, 248, 248, 248, 248, 248, 248, 248, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 225, 225, 225, 225, 225, 225, 225, 225, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186,   5,   5,   5,   5,   5,   5,   5,   5, 168, 168,\n",
      "        168, 168, 168, 168, 168, 168, 163, 163, 163, 163, 163, 163, 163, 163,\n",
      "        253, 253, 253, 253, 253, 253, 253, 253], dtype=torch.int32)\n",
      "tensor(1.0698, grad_fn=<MeanBackward0>)\n",
      "tensor([283, 283, 283, 283, 283, 283, 283, 283,  48,  48,  48,  48,  48,  48,\n",
      "         48,  48, 166, 166, 166, 166, 166, 166, 166, 166, 194, 194, 194, 194,\n",
      "        194, 194, 194, 194,  42,  42,  42,  42,  42,  42,  42,  42, 180, 180,\n",
      "        180, 180, 180, 180, 180, 180, 272, 272, 272, 272, 272, 272, 272, 272,\n",
      "        284, 284, 284, 284, 284, 284, 284, 284], dtype=torch.int32)\n",
      "tensor(0.0907, grad_fn=<MeanBackward0>)\n",
      "tensor([266, 266, 266, 266, 266, 266, 266, 266, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154,  17,  17,  17,  17,  17,  17,  17,  17,  40,  40,  40,  40,\n",
      "         40,  40,  40,  40,  30,  30,  30,  30,  30,  30,  30,  30, 126, 126,\n",
      "        126, 126, 126, 126, 126, 126, 153, 153, 153, 153, 153, 153, 153, 153,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50], dtype=torch.int32)\n",
      "tensor(0.3464, grad_fn=<MeanBackward0>)\n",
      "tensor([233, 233, 233, 233, 233, 233, 233, 233, 224, 224, 224, 224, 224, 224,\n",
      "        224, 224,  71,  71,  71,  71,  71,  71,  71,  71, 230, 230, 230, 230,\n",
      "        230, 230, 230, 230, 122, 122, 122, 122, 122, 122, 122, 122, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25], dtype=torch.int32)\n",
      "tensor(0.3853, grad_fn=<MeanBackward0>)\n",
      "tensor([  4,   4,   4,   4,   4,   4,   4,   4, 130, 130, 130, 130, 130, 130,\n",
      "        130, 130, 267, 267, 267, 267, 267, 267, 267, 267,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,  45,  45,  45,  45,  45,  45,  45,  45, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         13,  13,  13,  13,  13,  13,  13,  13], dtype=torch.int32)\n",
      "tensor(0.8297, grad_fn=<MeanBackward0>)\n",
      "tensor([  0,   0,   0,   0,   0,   0,   0,   0, 284, 284, 284, 284, 284, 284,\n",
      "        284, 284,  44,  44,  44,  44,  44,  44,  44,  44,  85,  85,  85,  85,\n",
      "         85,  85,  85,  85, 128, 128, 128, 128, 128, 128, 128, 128, 233, 233,\n",
      "        233, 233, 233, 233, 233, 233,  83,  83,  83,  83,  83,  83,  83,  83,\n",
      "         59,  59,  59,  59,  59,  59,  59,  59], dtype=torch.int32)\n",
      "tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "tensor([ 27,  27,  27,  27,  27,  27,  27,  27, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 179, 179, 179, 179, 179, 179, 179, 179, 188, 188, 188, 188,\n",
      "        188, 188, 188, 188, 258, 258, 258, 258, 258, 258, 258, 258, 265, 265,\n",
      "        265, 265, 265, 265, 265, 265, 230, 230, 230, 230, 230, 230, 230, 230,\n",
      "        227, 227, 227, 227, 227, 227, 227, 227], dtype=torch.int32)\n",
      "tensor(0.3065, grad_fn=<MeanBackward0>)\n",
      "tensor([190, 190, 190, 190, 190, 190, 190, 190, 210, 210, 210, 210, 210, 210,\n",
      "        210, 210, 265, 265, 265, 265, 265, 265, 265, 265, 266, 266, 266, 266,\n",
      "        266, 266, 266, 266,  49,  49,  49,  49,  49,  49,  49,  49, 249, 249,\n",
      "        249, 249, 249, 249, 249, 249, 181, 181, 181, 181, 181, 181, 181, 181,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133], dtype=torch.int32)\n",
      "tensor(0.7539, grad_fn=<MeanBackward0>)\n",
      "tensor([211, 211, 211, 211, 211, 211, 211, 211,  15,  15,  15,  15,  15,  15,\n",
      "         15,  15, 193, 193, 193, 193, 193, 193, 193, 193, 188, 188, 188, 188,\n",
      "        188, 188, 188, 188,  82,  82,  82,  82,  82,  82,  82,  82, 174, 174,\n",
      "        174, 174, 174, 174, 174, 174, 246, 246, 246, 246, 246, 246, 246, 246,\n",
      "         62,  62,  62,  62,  62,  62,  62,  62], dtype=torch.int32)\n",
      "tensor(0.7191, grad_fn=<MeanBackward0>)\n",
      "tensor([220, 220, 220, 220, 220, 220, 220, 220, 257, 257, 257, 257, 257, 257,\n",
      "        257, 257, 139, 139, 139, 139, 139, 139, 139, 139, 173, 173, 173, 173,\n",
      "        173, 173, 173, 173, 195, 195, 195, 195, 195, 195, 195, 195, 265, 265,\n",
      "        265, 265, 265, 265, 265, 265, 242, 242, 242, 242, 242, 242, 242, 242,\n",
      "         93,  93,  93,  93,  93,  93,  93,  93], dtype=torch.int32)\n",
      "tensor(0.3844, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([220, 220, 220, 220, 220, 220, 220, 220, 239, 239, 239, 239, 239, 239,\n",
      "        239, 239, 176, 176, 176, 176, 176, 176, 176, 176,  76,  76,  76,  76,\n",
      "         76,  76,  76,  76, 251, 251, 251, 251, 251, 251, 251, 251, 178, 178,\n",
      "        178, 178, 178, 178, 178, 178,  63,  63,  63,  63,  63,  63,  63,  63,\n",
      "        279, 279, 279, 279, 279, 279, 279, 279], dtype=torch.int32)\n",
      "tensor(0.5358, grad_fn=<MeanBackward0>)\n",
      "tensor([ 87,  87,  87,  87,  87,  87,  87,  87, 282, 282, 282, 282, 282, 282,\n",
      "        282, 282,   1,   1,   1,   1,   1,   1,   1,   1, 275, 275, 275, 275,\n",
      "        275, 275, 275, 275,   5,   5,   5,   5,   5,   5,   5,   5, 269, 269,\n",
      "        269, 269, 269, 269, 269, 269,  84,  84,  84,  84,  84,  84,  84,  84,\n",
      "        252, 252, 252, 252, 252, 252, 252, 252], dtype=torch.int32)\n",
      "tensor(0.6907, grad_fn=<MeanBackward0>)\n",
      "tensor([276, 276, 276, 276, 276, 276, 276, 276, 219, 219, 219, 219, 219, 219,\n",
      "        219, 219, 171, 171, 171, 171, 171, 171, 171, 171, 237, 237, 237, 237,\n",
      "        237, 237, 237, 237,  88,  88,  88,  88,  88,  88,  88,  88,  39,  39,\n",
      "         39,  39,  39,  39,  39,  39,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "        157, 157, 157, 157, 157, 157, 157, 157], dtype=torch.int32)\n",
      "tensor(0.3598, grad_fn=<MeanBackward0>)\n",
      "tensor([ 43,  43,  43,  43,  43,  43,  43,  43, 283, 283, 283, 283, 283, 283,\n",
      "        283, 283, 121, 121, 121, 121, 121, 121, 121, 121, 285, 285, 285, 285,\n",
      "        285, 285, 285, 285, 228, 228, 228, 228, 228, 228, 228, 228,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27, 237, 237, 237, 237, 237, 237, 237, 237,\n",
      "         84,  84,  84,  84,  84,  84,  84,  84], dtype=torch.int32)\n",
      "tensor(0.3474, grad_fn=<MeanBackward0>)\n",
      "tensor([235, 235, 235, 235, 235, 235, 235, 235, 263, 263, 263, 263, 263, 263,\n",
      "        263, 263, 171, 171, 171, 171, 171, 171, 171, 171, 245, 245, 245, 245,\n",
      "        245, 245, 245, 245, 262, 262, 262, 262, 262, 262, 262, 262,  80,  80,\n",
      "         80,  80,  80,  80,  80,  80,  45,  45,  45,  45,  45,  45,  45,  45,\n",
      "         47,  47,  47,  47,  47,  47,  47,  47], dtype=torch.int32)\n",
      "tensor(0.3119, grad_fn=<MeanBackward0>)\n",
      "tensor([ 74,  74,  74,  74,  74,  74,  74,  74,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82, 288, 288, 288, 288, 288, 288, 288, 288,  80,  80,  80,  80,\n",
      "         80,  80,  80,  80,   2,   2,   2,   2,   2,   2,   2,   2, 158, 158,\n",
      "        158, 158, 158, 158, 158, 158, 109, 109, 109, 109, 109, 109, 109, 109,\n",
      "         63,  63,  63,  63,  63,  63,  63,  63], dtype=torch.int32)\n",
      "tensor(0.2620, grad_fn=<MeanBackward0>)\n",
      "tensor([ 79,  79,  79,  79,  79,  79,  79,  79, 145, 145, 145, 145, 145, 145,\n",
      "        145, 145, 137, 137, 137, 137, 137, 137, 137, 137, 238, 238, 238, 238,\n",
      "        238, 238, 238, 238, 101, 101, 101, 101, 101, 101, 101, 101,  74,  74,\n",
      "         74,  74,  74,  74,  74,  74, 131, 131, 131, 131, 131, 131, 131, 131,\n",
      "        167, 167, 167, 167, 167, 167, 167, 167], dtype=torch.int32)\n",
      "tensor(0.7446, grad_fn=<MeanBackward0>)\n",
      "tensor([173, 173, 173, 173, 173, 173, 173, 173, 108, 108, 108, 108, 108, 108,\n",
      "        108, 108, 251, 251, 251, 251, 251, 251, 251, 251,  75,  75,  75,  75,\n",
      "         75,  75,  75,  75,  16,  16,  16,  16,  16,  16,  16,  16, 272, 272,\n",
      "        272, 272, 272, 272, 272, 272, 281, 281, 281, 281, 281, 281, 281, 281,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132], dtype=torch.int32)\n",
      "tensor(0.3335, grad_fn=<MeanBackward0>)\n",
      "tensor([  4,   4,   4,   4,   4,   4,   4,   4,  74,  74,  74,  74,  74,  74,\n",
      "         74,  74, 113, 113, 113, 113, 113, 113, 113, 113, 162, 162, 162, 162,\n",
      "        162, 162, 162, 162, 153, 153, 153, 153, 153, 153, 153, 153, 152, 152,\n",
      "        152, 152, 152, 152, 152, 152,  71,  71,  71,  71,  71,  71,  71,  71,\n",
      "        104, 104, 104, 104, 104, 104, 104, 104], dtype=torch.int32)\n",
      "tensor(0.2456, grad_fn=<MeanBackward0>)\n",
      "tensor([ 39,  39,  39,  39,  39,  39,  39,  39, 208, 208, 208, 208, 208, 208,\n",
      "        208, 208,  80,  80,  80,  80,  80,  80,  80,  80, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154,  12,  12,  12,  12,  12,  12,  12,  12,  51,  51,\n",
      "         51,  51,  51,  51,  51,  51, 158, 158, 158, 158, 158, 158, 158, 158,\n",
      "        234, 234, 234, 234, 234, 234, 234, 234], dtype=torch.int32)\n",
      "tensor(0.3922, grad_fn=<MeanBackward0>)\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144, 119, 119, 119, 119, 119, 119,\n",
      "        119, 119,  64,  64,  64,  64,  64,  64,  64,  64,  12,  12,  12,  12,\n",
      "         12,  12,  12,  12, 280, 280, 280, 280, 280, 280, 280, 280, 263, 263,\n",
      "        263, 263, 263, 263, 263, 263, 135, 135, 135, 135, 135, 135, 135, 135,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122], dtype=torch.int32)\n",
      "tensor(0.7678, grad_fn=<MeanBackward0>)\n",
      "tensor([184, 184, 184, 184, 184, 184, 184, 184, 162, 162, 162, 162, 162, 162,\n",
      "        162, 162, 113, 113, 113, 113, 113, 113, 113, 113, 226, 226, 226, 226,\n",
      "        226, 226, 226, 226, 101, 101, 101, 101, 101, 101, 101, 101, 202, 202,\n",
      "        202, 202, 202, 202, 202, 202,  10,  10,  10,  10,  10,  10,  10,  10,\n",
      "        191, 191, 191, 191, 191, 191, 191, 191], dtype=torch.int32)\n",
      "tensor(0.3407, grad_fn=<MeanBackward0>)\n",
      "tensor([139, 139, 139, 139, 139, 139, 139, 139, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114, 169, 169, 169, 169, 169, 169, 169, 169, 194, 194, 194, 194,\n",
      "        194, 194, 194, 194, 280, 280, 280, 280, 280, 280, 280, 280, 157, 157,\n",
      "        157, 157, 157, 157, 157, 157, 259, 259, 259, 259, 259, 259, 259, 259,\n",
      "         98,  98,  98,  98,  98,  98,  98,  98], dtype=torch.int32)\n",
      "tensor(0.5844, grad_fn=<MeanBackward0>)\n",
      "tensor([ 37,  37,  37,  37,  37,  37,  37,  37, 137, 137, 137, 137, 137, 137,\n",
      "        137, 137,  16,  16,  16,  16,  16,  16,  16,  16, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140, 243, 243, 243, 243, 243, 243, 243, 243,  14,  14,\n",
      "         14,  14,  14,  14,  14,  14, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        180, 180, 180, 180, 180, 180, 180, 180], dtype=torch.int32)\n",
      "tensor(0.2824, grad_fn=<MeanBackward0>)\n",
      "tensor([ 41,  41,  41,  41,  41,  41,  41,  41, 199, 199, 199, 199, 199, 199,\n",
      "        199, 199, 159, 159, 159, 159, 159, 159, 159, 159, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 218, 218, 218, 218, 218, 218, 218, 218,  15,  15,\n",
      "         15,  15,  15,  15,  15,  15,  39,  39,  39,  39,  39,  39,  39,  39,\n",
      "        104, 104, 104, 104, 104, 104, 104, 104], dtype=torch.int32)\n",
      "tensor(0.4141, grad_fn=<MeanBackward0>)\n",
      "tensor([ 87,  87,  87,  87,  87,  87,  87,  87, 258, 258, 258, 258, 258, 258,\n",
      "        258, 258,   9,   9,   9,   9,   9,   9,   9,   9, 126, 126, 126, 126,\n",
      "        126, 126, 126, 126, 163, 163, 163, 163, 163, 163, 163, 163,  22,  22,\n",
      "         22,  22,  22,  22,  22,  22, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        274, 274, 274, 274, 274, 274, 274, 274], dtype=torch.int32)\n",
      "tensor(0.5224, grad_fn=<MeanBackward0>)\n",
      "tensor([ 22,  22,  22,  22,  22,  22,  22,  22, 259, 259, 259, 259, 259, 259,\n",
      "        259, 259,  44,  44,  44,  44,  44,  44,  44,  44, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 256, 256, 256, 256, 256, 256, 256, 256, 238, 238,\n",
      "        238, 238, 238, 238, 238, 238, 252, 252, 252, 252, 252, 252, 252, 252,\n",
      "        189, 189, 189, 189, 189, 189, 189, 189], dtype=torch.int32)\n",
      "tensor(0.3313, grad_fn=<MeanBackward0>)\n",
      "tensor([279, 279, 279, 279, 279, 279, 279, 279, 239, 239, 239, 239, 239, 239,\n",
      "        239, 239,  53,  53,  53,  53,  53,  53,  53,  53,  42,  42,  42,  42,\n",
      "         42,  42,  42,  42, 258, 258, 258, 258, 258, 258, 258, 258, 146, 146,\n",
      "        146, 146, 146, 146, 146, 146, 182, 182, 182, 182, 182, 182, 182, 182,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92], dtype=torch.int32)\n",
      "tensor(0.4929, grad_fn=<MeanBackward0>)\n",
      "tensor([117, 117, 117, 117, 117, 117, 117, 117,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68, 124, 124, 124, 124, 124, 124, 124, 124, 266, 266, 266, 266,\n",
      "        266, 266, 266, 266,  80,  80,  80,  80,  80,  80,  80,  80, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 170, 170, 170, 170, 170, 170, 170, 170,\n",
      "        257, 257, 257, 257, 257, 257, 257, 257], dtype=torch.int32)\n",
      "tensor(0.1269, grad_fn=<MeanBackward0>)\n",
      "tensor([263, 263, 263, 263, 263, 263, 263, 263, 106, 106, 106, 106, 106, 106,\n",
      "        106, 106, 135, 135, 135, 135, 135, 135, 135, 135, 229, 229, 229, 229,\n",
      "        229, 229, 229, 229, 205, 205, 205, 205, 205, 205, 205, 205,  88,  88,\n",
      "         88,  88,  88,  88,  88,  88, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        257, 257, 257, 257, 257, 257, 257, 257], dtype=torch.int32)\n",
      "tensor(0.1595, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([213, 213, 213, 213, 213, 213, 213, 213, 237, 237, 237, 237, 237, 237,\n",
      "        237, 237, 193, 193, 193, 193, 193, 193, 193, 193, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 207, 207, 207, 207, 207, 207, 207, 207, 281, 281,\n",
      "        281, 281, 281, 281, 281, 281, 254, 254, 254, 254, 254, 254, 254, 254,\n",
      "        158, 158, 158, 158, 158, 158, 158, 158], dtype=torch.int32)\n",
      "tensor(0.7917, grad_fn=<MeanBackward0>)\n",
      "tensor([128, 128, 128, 128, 128, 128, 128, 128,  66,  66,  66,  66,  66,  66,\n",
      "         66,  66, 237, 237, 237, 237, 237, 237, 237, 237, 279, 279, 279, 279,\n",
      "        279, 279, 279, 279, 275, 275, 275, 275, 275, 275, 275, 275,  41,  41,\n",
      "         41,  41,  41,  41,  41,  41, 191, 191, 191, 191, 191, 191, 191, 191,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125], dtype=torch.int32)\n",
      "tensor(0.4497, grad_fn=<MeanBackward0>)\n",
      "tensor([281, 281, 281, 281, 281, 281, 281, 281, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160,  28,  28,  28,  28,  28,  28,  28,  28,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,  27,  27,  27,  27,  27,  27,  27,  27,  15,  15,\n",
      "         15,  15,  15,  15,  15,  15,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232], dtype=torch.int32)\n",
      "tensor(0.2538, grad_fn=<MeanBackward0>)\n",
      "tensor([ 33,  33,  33,  33,  33,  33,  33,  33,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  20,  20,  20,  20,  20,  20,  20,  20, 250, 250, 250, 250,\n",
      "        250, 250, 250, 250,  32,  32,  32,  32,  32,  32,  32,  32,  39,  39,\n",
      "         39,  39,  39,  39,  39,  39, 264, 264, 264, 264, 264, 264, 264, 264,\n",
      "         11,  11,  11,  11,  11,  11,  11,  11], dtype=torch.int32)\n",
      "tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "tensor([ 29,  29,  29,  29,  29,  29,  29,  29, 183, 183, 183, 183, 183, 183,\n",
      "        183, 183,  59,  59,  59,  59,  59,  59,  59,  59, 264, 264, 264, 264,\n",
      "        264, 264, 264, 264, 136, 136, 136, 136, 136, 136, 136, 136,  19,  19,\n",
      "         19,  19,  19,  19,  19,  19,  55,  55,  55,  55,  55,  55,  55,  55,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24], dtype=torch.int32)\n",
      "tensor(0.6530, grad_fn=<MeanBackward0>)\n",
      "tensor([224, 224, 224, 224, 224, 224, 224, 224, 230, 230, 230, 230, 230, 230,\n",
      "        230, 230,  31,  31,  31,  31,  31,  31,  31,  31, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 236, 236, 236, 236, 236, 236, 236, 236,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,  94,  94,  94,  94,  94,  94,  94,  94,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122], dtype=torch.int32)\n",
      "tensor(0.2873, grad_fn=<MeanBackward0>)\n",
      "tensor([ 95,  95,  95,  95,  95,  95,  95,  95, 219, 219, 219, 219, 219, 219,\n",
      "        219, 219,  91,  91,  91,  91,  91,  91,  91,  91, 283, 283, 283, 283,\n",
      "        283, 283, 283, 283, 244, 244, 244, 244, 244, 244, 244, 244,  22,  22,\n",
      "         22,  22,  22,  22,  22,  22, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25], dtype=torch.int32)\n",
      "tensor(0.6416, grad_fn=<MeanBackward0>)\n",
      "tensor([145, 145, 145, 145, 145, 145, 145, 145, 162, 162, 162, 162, 162, 162,\n",
      "        162, 162,  32,  32,  32,  32,  32,  32,  32,  32, 288, 288, 288, 288,\n",
      "        288, 288, 288, 288,  91,  91,  91,  91,  91,  91,  91,  91, 287, 287,\n",
      "        287, 287, 287, 287, 287, 287, 290, 290, 290, 290, 290, 290, 290, 290,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140], dtype=torch.int32)\n",
      "tensor(0.9611, grad_fn=<MeanBackward0>)\n",
      "tensor([266, 266, 266, 266, 266, 266, 266, 266, 175, 175, 175, 175, 175, 175,\n",
      "        175, 175, 284, 284, 284, 284, 284, 284, 284, 284, 153, 153, 153, 153,\n",
      "        153, 153, 153, 153,  59,  59,  59,  59,  59,  59,  59,  59,  89,  89,\n",
      "         89,  89,  89,  89,  89,  89,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "        230, 230, 230, 230, 230, 230, 230, 230], dtype=torch.int32)\n",
      "tensor(0.3072, grad_fn=<MeanBackward0>)\n",
      "tensor([113, 113, 113, 113, 113, 113, 113, 113, 238, 238, 238, 238, 238, 238,\n",
      "        238, 238, 221, 221, 221, 221, 221, 221, 221, 221, 207, 207, 207, 207,\n",
      "        207, 207, 207, 207,  47,  47,  47,  47,  47,  47,  47,  47,  18,  18,\n",
      "         18,  18,  18,  18,  18,  18, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "        130, 130, 130, 130, 130, 130, 130, 130], dtype=torch.int32)\n",
      "tensor(0.3354, grad_fn=<MeanBackward0>)\n",
      "tensor([115, 115, 115, 115, 115, 115, 115, 115, 126, 126, 126, 126, 126, 126,\n",
      "        126, 126, 203, 203, 203, 203, 203, 203, 203, 203, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165,  76,  76,  76,  76,  76,  76,  76,  76,  21,  21,\n",
      "         21,  21,  21,  21,  21,  21,  80,  80,  80,  80,  80,  80,  80,  80,\n",
      "        246, 246, 246, 246, 246, 246, 246, 246], dtype=torch.int32)\n",
      "tensor(0.1797, grad_fn=<MeanBackward0>)\n",
      "tensor([249, 249, 249, 249, 249, 249, 249, 249, 184, 184, 184, 184, 184, 184,\n",
      "        184, 184, 277, 277, 277, 277, 277, 277, 277, 277, 238, 238, 238, 238,\n",
      "        238, 238, 238, 238, 140, 140, 140, 140, 140, 140, 140, 140, 276, 276,\n",
      "        276, 276, 276, 276, 276, 276, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "         69,  69,  69,  69,  69,  69,  69,  69], dtype=torch.int32)\n",
      "tensor(0.6751, grad_fn=<MeanBackward0>)\n",
      "tensor([173, 173, 173, 173, 173, 173, 173, 173,  69,  69,  69,  69,  69,  69,\n",
      "         69,  69, 118, 118, 118, 118, 118, 118, 118, 118,  10,  10,  10,  10,\n",
      "         10,  10,  10,  10, 221, 221, 221, 221, 221, 221, 221, 221, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161,  93,  93,  93,  93,  93,  93,  93,  93,\n",
      "        272, 272, 272, 272, 272, 272, 272, 272], dtype=torch.int32)\n",
      "tensor(0.2484, grad_fn=<MeanBackward0>)\n",
      "tensor([  5,   5,   5,   5,   5,   5,   5,   5, 111, 111, 111, 111, 111, 111,\n",
      "        111, 111, 229, 229, 229, 229, 229, 229, 229, 229,  87,  87,  87,  87,\n",
      "         87,  87,  87,  87, 272, 272, 272, 272, 272, 272, 272, 272,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7, 281, 281, 281, 281, 281, 281, 281, 281,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147], dtype=torch.int32)\n",
      "tensor(0.0971, grad_fn=<MeanBackward0>)\n",
      "tensor([141, 141, 141, 141, 141, 141, 141, 141, 153, 153, 153, 153, 153, 153,\n",
      "        153, 153,  25,  25,  25,  25,  25,  25,  25,  25, 191, 191, 191, 191,\n",
      "        191, 191, 191, 191, 262, 262, 262, 262, 262, 262, 262, 262,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16, 223, 223, 223, 223, 223, 223, 223, 223,\n",
      "        285, 285, 285, 285, 285, 285, 285, 285], dtype=torch.int32)\n",
      "tensor(0.4745, grad_fn=<MeanBackward0>)\n",
      "tensor([145, 145, 145, 145, 145, 145, 145, 145, 182, 182, 182, 182, 182, 182,\n",
      "        182, 182,  61,  61,  61,  61,  61,  61,  61,  61, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 231, 231, 231, 231, 231, 231, 231, 231,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,  75,  75,  75,  75,  75,  75,  75,  75,\n",
      "        275, 275, 275, 275, 275, 275, 275, 275], dtype=torch.int32)\n",
      "tensor(0.4835, grad_fn=<MeanBackward0>)\n",
      "tensor([123, 123, 123, 123, 123, 123, 123, 123, 169, 169, 169, 169, 169, 169,\n",
      "        169, 169, 222, 222, 222, 222, 222, 222, 222, 222, 268, 268, 268, 268,\n",
      "        268, 268, 268, 268,  74,  74,  74,  74,  74,  74,  74,  74, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 163, 163, 163, 163, 163, 163, 163, 163,\n",
      "        180, 180, 180, 180, 180, 180, 180, 180], dtype=torch.int32)\n",
      "tensor(0.3117, grad_fn=<MeanBackward0>)\n",
      "tensor([110, 110, 110, 110, 110, 110, 110, 110, 241, 241, 241, 241, 241, 241,\n",
      "        241, 241,  39,  39,  39,  39,  39,  39,  39,  39, 273, 273, 273, 273,\n",
      "        273, 273, 273, 273,  17,  17,  17,  17,  17,  17,  17,  17, 170, 170,\n",
      "        170, 170, 170, 170, 170, 170, 178, 178, 178, 178, 178, 178, 178, 178,\n",
      "         99,  99,  99,  99,  99,  99,  99,  99], dtype=torch.int32)\n",
      "tensor(0.4339, grad_fn=<MeanBackward0>)\n",
      "tensor([259, 259, 259, 259, 259, 259, 259, 259, 210, 210, 210, 210, 210, 210,\n",
      "        210, 210,  13,  13,  13,  13,  13,  13,  13,  13,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  81,  81,  81,  81,  81,  81,  81,  81, 191, 191,\n",
      "        191, 191, 191, 191, 191, 191, 117, 117, 117, 117, 117, 117, 117, 117,\n",
      "        105, 105, 105, 105, 105, 105, 105, 105], dtype=torch.int32)\n",
      "tensor(0.4059, grad_fn=<MeanBackward0>)\n",
      "tensor([289, 289, 289, 289, 289, 289, 289, 289, 253, 253, 253, 253, 253, 253,\n",
      "        253, 253, 213, 213, 213, 213, 213, 213, 213, 213, 149, 149, 149, 149,\n",
      "        149, 149, 149, 149, 270, 270, 270, 270, 270, 270, 270, 270, 208, 208,\n",
      "        208, 208, 208, 208, 208, 208, 207, 207, 207, 207, 207, 207, 207, 207,\n",
      "        164, 164, 164, 164, 164, 164, 164, 164], dtype=torch.int32)\n",
      "tensor(0.8558, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([248, 248, 248, 248, 248, 248, 248, 248, 170, 170, 170, 170, 170, 170,\n",
      "        170, 170,  65,  65,  65,  65,  65,  65,  65,  65,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,   7,   7,   7,   7,   7,   7,   7,   7, 184, 184,\n",
      "        184, 184, 184, 184, 184, 184, 288, 288, 288, 288, 288, 288, 288, 288,\n",
      "        260, 260, 260, 260, 260, 260, 260, 260], dtype=torch.int32)\n",
      "tensor(0.1244, grad_fn=<MeanBackward0>)\n",
      "tensor([255, 255, 255, 255, 255, 255, 255, 255,   9,   9,   9,   9,   9,   9,\n",
      "          9,   9, 258, 258, 258, 258, 258, 258, 258, 258, 251, 251, 251, 251,\n",
      "        251, 251, 251, 251, 167, 167, 167, 167, 167, 167, 167, 167, 213, 213,\n",
      "        213, 213, 213, 213, 213, 213, 208, 208, 208, 208, 208, 208, 208, 208,\n",
      "         77,  77,  77,  77,  77,  77,  77,  77], dtype=torch.int32)\n",
      "tensor(0.7357, grad_fn=<MeanBackward0>)\n",
      "tensor([124, 124, 124, 124, 124, 124, 124, 124,  88,  88,  88,  88,  88,  88,\n",
      "         88,  88, 277, 277, 277, 277, 277, 277, 277, 277, 121, 121, 121, 121,\n",
      "        121, 121, 121, 121, 101, 101, 101, 101, 101, 101, 101, 101, 227, 227,\n",
      "        227, 227, 227, 227, 227, 227,   9,   9,   9,   9,   9,   9,   9,   9,\n",
      "        144, 144, 144, 144, 144, 144, 144, 144], dtype=torch.int32)\n",
      "tensor(0.6564, grad_fn=<MeanBackward0>)\n",
      "tensor([172, 172, 172, 172, 172, 172, 172, 172, 188, 188, 188, 188, 188, 188,\n",
      "        188, 188,  49,  49,  49,  49,  49,  49,  49,  49,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92, 180, 180, 180, 180, 180, 180, 180, 180,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38, 249, 249, 249, 249, 249, 249, 249, 249,\n",
      "        159, 159, 159, 159, 159, 159, 159, 159], dtype=torch.int32)\n",
      "tensor(0.1114, grad_fn=<MeanBackward0>)\n",
      "tensor([255, 255, 255, 255, 255, 255, 255, 255,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  37,  37,  37,  37,  37,  37,  37,  37, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 168, 168, 168, 168, 168, 168, 168, 168,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        108, 108, 108, 108, 108, 108, 108, 108], dtype=torch.int32)\n",
      "tensor(0.5357, grad_fn=<MeanBackward0>)\n",
      "tensor([114, 114, 114, 114, 114, 114, 114, 114,  63,  63,  63,  63,  63,  63,\n",
      "         63,  63, 185, 185, 185, 185, 185, 185, 185, 185, 239, 239, 239, 239,\n",
      "        239, 239, 239, 239,  84,  84,  84,  84,  84,  84,  84,  84, 202, 202,\n",
      "        202, 202, 202, 202, 202, 202,  69,  69,  69,  69,  69,  69,  69,  69,\n",
      "        225, 225, 225, 225, 225, 225, 225, 225], dtype=torch.int32)\n",
      "tensor(0.9520, grad_fn=<MeanBackward0>)\n",
      "tensor([ 37,  37,  37,  37,  37,  37,  37,  37, 122, 122, 122, 122, 122, 122,\n",
      "        122, 122,  67,  67,  67,  67,  67,  67,  67,  67,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17, 114, 114, 114, 114, 114, 114, 114, 114, 234, 234,\n",
      "        234, 234, 234, 234, 234, 234,  87,  87,  87,  87,  87,  87,  87,  87,\n",
      "        226, 226, 226, 226, 226, 226, 226, 226], dtype=torch.int32)\n",
      "tensor(0.1396, grad_fn=<MeanBackward0>)\n",
      "tensor([120, 120, 120, 120, 120, 120, 120, 120, 252, 252, 252, 252, 252, 252,\n",
      "        252, 252, 165, 165, 165, 165, 165, 165, 165, 165,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52, 242, 242, 242, 242, 242, 242, 242, 242, 237, 237,\n",
      "        237, 237, 237, 237, 237, 237, 272, 272, 272, 272, 272, 272, 272, 272,\n",
      "        286, 286, 286, 286, 286, 286, 286, 286], dtype=torch.int32)\n",
      "tensor(0.2117, grad_fn=<MeanBackward0>)\n",
      "tensor([155, 155, 155, 155, 155, 155, 155, 155,  23,  23,  23,  23,  23,  23,\n",
      "         23,  23, 200, 200, 200, 200, 200, 200, 200, 200, 236, 236, 236, 236,\n",
      "        236, 236, 236, 236,  93,  93,  93,  93,  93,  93,  93,  93, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123,  36,  36,  36,  36,  36,  36,  36,  36,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118], dtype=torch.int32)\n",
      "tensor(0.1802, grad_fn=<MeanBackward0>)\n",
      "tensor([263, 263, 263, 263, 263, 263, 263, 263, 205, 205, 205, 205, 205, 205,\n",
      "        205, 205, 147, 147, 147, 147, 147, 147, 147, 147, 229, 229, 229, 229,\n",
      "        229, 229, 229, 229, 256, 256, 256, 256, 256, 256, 256, 256,  18,  18,\n",
      "         18,  18,  18,  18,  18,  18,  33,  33,  33,  33,  33,  33,  33,  33,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125], dtype=torch.int32)\n",
      "tensor(0.3229, grad_fn=<MeanBackward0>)\n",
      "tensor([269, 269, 269, 269, 269, 269, 269, 269, 275, 275, 275, 275, 275, 275,\n",
      "        275, 275,  53,  53,  53,  53,  53,  53,  53,  53,  98,  98,  98,  98,\n",
      "         98,  98,  98,  98, 226, 226, 226, 226, 226, 226, 226, 226, 125, 125,\n",
      "        125, 125, 125, 125, 125, 125, 239, 239, 239, 239, 239, 239, 239, 239,\n",
      "         33,  33,  33,  33,  33,  33,  33,  33], dtype=torch.int32)\n",
      "tensor(0.8327, grad_fn=<MeanBackward0>)\n",
      "tensor([207, 207, 207, 207, 207, 207, 207, 207, 218, 218, 218, 218, 218, 218,\n",
      "        218, 218, 135, 135, 135, 135, 135, 135, 135, 135, 198, 198, 198, 198,\n",
      "        198, 198, 198, 198, 272, 272, 272, 272, 272, 272, 272, 272, 254, 254,\n",
      "        254, 254, 254, 254, 254, 254,  84,  84,  84,  84,  84,  84,  84,  84,\n",
      "         67,  67,  67,  67,  67,  67,  67,  67], dtype=torch.int32)\n",
      "tensor(0.1364, grad_fn=<MeanBackward0>)\n",
      "tensor([ 39,  39,  39,  39,  39,  39,  39,  39, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 117, 117, 117, 117, 117, 117, 117, 117, 181, 181, 181, 181,\n",
      "        181, 181, 181, 181, 166, 166, 166, 166, 166, 166, 166, 166, 200, 200,\n",
      "        200, 200, 200, 200, 200, 200, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "         66,  66,  66,  66,  66,  66,  66,  66], dtype=torch.int32)\n",
      "tensor(0.1694, grad_fn=<MeanBackward0>)\n",
      "tensor([276, 276, 276, 276, 276, 276, 276, 276, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171,  86,  86,  86,  86,  86,  86,  86,  86, 163, 163, 163, 163,\n",
      "        163, 163, 163, 163, 115, 115, 115, 115, 115, 115, 115, 115,  99,  99,\n",
      "         99,  99,  99,  99,  99,  99, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149], dtype=torch.int32)\n",
      "tensor(0.4215, grad_fn=<MeanBackward0>)\n",
      "tensor([ 66,  66,  66,  66,  66,  66,  66,  66, 214, 214, 214, 214, 214, 214,\n",
      "        214, 214, 270, 270, 270, 270, 270, 270, 270, 270, 125, 125, 125, 125,\n",
      "        125, 125, 125, 125, 237, 237, 237, 237, 237, 237, 237, 237, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132,  51,  51,  51,  51,  51,  51,  51,  51,\n",
      "        131, 131, 131, 131, 131, 131, 131, 131], dtype=torch.int32)\n",
      "tensor(0.4431, grad_fn=<MeanBackward0>)\n",
      "tensor([275, 275, 275, 275, 275, 275, 275, 275, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 252, 252, 252, 252, 252, 252, 252, 252,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   9,   9,   9,   9,   9,   9,   9,   9, 266, 266,\n",
      "        266, 266, 266, 266, 266, 266,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        238, 238, 238, 238, 238, 238, 238, 238], dtype=torch.int32)\n",
      "tensor(0.3172, grad_fn=<MeanBackward0>)\n",
      "tensor([ 97,  97,  97,  97,  97,  97,  97,  97, 211, 211, 211, 211, 211, 211,\n",
      "        211, 211,  39,  39,  39,  39,  39,  39,  39,  39, 249, 249, 249, 249,\n",
      "        249, 249, 249, 249, 142, 142, 142, 142, 142, 142, 142, 142, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "         34,  34,  34,  34,  34,  34,  34,  34], dtype=torch.int32)\n",
      "tensor(0.2785, grad_fn=<MeanBackward0>)\n",
      "tensor([191, 191, 191, 191, 191, 191, 191, 191, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 208, 208, 208, 208, 208, 208, 208, 208, 270, 270, 270, 270,\n",
      "        270, 270, 270, 270,  34,  34,  34,  34,  34,  34,  34,  34, 181, 181,\n",
      "        181, 181, 181, 181, 181, 181, 242, 242, 242, 242, 242, 242, 242, 242,\n",
      "        245, 245, 245, 245, 245, 245, 245, 245], dtype=torch.int32)\n",
      "tensor(0.8935, grad_fn=<MeanBackward0>)\n",
      "tensor([202, 202, 202, 202, 202, 202, 202, 202, 125, 125, 125, 125, 125, 125,\n",
      "        125, 125,  93,  93,  93,  93,  93,  93,  93,  93, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212,  26,  26,  26,  26,  26,  26,  26,  26,  49,  49,\n",
      "         49,  49,  49,  49,  49,  49, 137, 137, 137, 137, 137, 137, 137, 137,\n",
      "         94,  94,  94,  94,  94,  94,  94,  94], dtype=torch.int32)\n",
      "tensor(0.4387, grad_fn=<MeanBackward0>)\n",
      "tensor([158, 158, 158, 158, 158, 158, 158, 158, 287, 287, 287, 287, 287, 287,\n",
      "        287, 287, 135, 135, 135, 135, 135, 135, 135, 135,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  25,  25,  25,  25,  25,  25,  25,  25, 258, 258,\n",
      "        258, 258, 258, 258, 258, 258,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         63,  63,  63,  63,  63,  63,  63,  63], dtype=torch.int32)\n",
      "tensor(0.6065, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([104, 104, 104, 104, 104, 104, 104, 104,  33,  33,  33,  33,  33,  33,\n",
      "         33,  33,  53,  53,  53,  53,  53,  53,  53,  53, 184, 184, 184, 184,\n",
      "        184, 184, 184, 184, 142, 142, 142, 142, 142, 142, 142, 142, 267, 267,\n",
      "        267, 267, 267, 267, 267, 267,  11,  11,  11,  11,  11,  11,  11,  11,\n",
      "        228, 228, 228, 228, 228, 228, 228, 228], dtype=torch.int32)\n",
      "tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor([129, 129, 129, 129, 129, 129, 129, 129,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99, 231, 231, 231, 231, 231, 231, 231, 231,  88,  88,  88,  88,\n",
      "         88,  88,  88,  88, 162, 162, 162, 162, 162, 162, 162, 162,  79,  79,\n",
      "         79,  79,  79,  79,  79,  79,  45,  45,  45,  45,  45,  45,  45,  45,\n",
      "        270, 270, 270, 270, 270, 270, 270, 270], dtype=torch.int32)\n",
      "tensor(0.2202, grad_fn=<MeanBackward0>)\n",
      "tensor([203, 203, 203, 203, 203, 203, 203, 203,  44,  44,  44,  44,  44,  44,\n",
      "         44,  44,  64,  64,  64,  64,  64,  64,  64,  64,  53,  53,  53,  53,\n",
      "         53,  53,  53,  53,  95,  95,  95,  95,  95,  95,  95,  95, 169, 169,\n",
      "        169, 169, 169, 169, 169, 169, 211, 211, 211, 211, 211, 211, 211, 211,\n",
      "         37,  37,  37,  37,  37,  37,  37,  37], dtype=torch.int32)\n",
      "tensor(0.5775, grad_fn=<MeanBackward0>)\n",
      "tensor([  9,   9,   9,   9,   9,   9,   9,   9,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  72,  72,  72,  72,  72,  72,  72,  72, 152, 152, 152, 152,\n",
      "        152, 152, 152, 152, 253, 253, 253, 253, 253, 253, 253, 253, 262, 262,\n",
      "        262, 262, 262, 262, 262, 262, 273, 273, 273, 273, 273, 273, 273, 273,\n",
      "        271, 271, 271, 271, 271, 271, 271, 271], dtype=torch.int32)\n",
      "tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "tensor([270, 270, 270, 270, 270, 270, 270, 270, 217, 217, 217, 217, 217, 217,\n",
      "        217, 217, 155, 155, 155, 155, 155, 155, 155, 155,  21,  21,  21,  21,\n",
      "         21,  21,  21,  21, 137, 137, 137, 137, 137, 137, 137, 137, 251, 251,\n",
      "        251, 251, 251, 251, 251, 251, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        259, 259, 259, 259, 259, 259, 259, 259], dtype=torch.int32)\n",
      "tensor(0.6076, grad_fn=<MeanBackward0>)\n",
      "tensor([101, 101, 101, 101, 101, 101, 101, 101, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114,  31,  31,  31,  31,  31,  31,  31,  31,  43,  43,  43,  43,\n",
      "         43,  43,  43,  43, 201, 201, 201, 201, 201, 201, 201, 201, 271, 271,\n",
      "        271, 271, 271, 271, 271, 271, 194, 194, 194, 194, 194, 194, 194, 194,\n",
      "          9,   9,   9,   9,   9,   9,   9,   9], dtype=torch.int32)\n",
      "tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "tensor([ 47,  47,  47,  47,  47,  47,  47,  47,  28,  28,  28,  28,  28,  28,\n",
      "         28,  28, 124, 124, 124, 124, 124, 124, 124, 124, 155, 155, 155, 155,\n",
      "        155, 155, 155, 155,  49,  49,  49,  49,  49,  49,  49,  49, 191, 191,\n",
      "        191, 191, 191, 191, 191, 191, 283, 283, 283, 283, 283, 283, 283, 283,\n",
      "        230, 230, 230, 230, 230, 230, 230, 230], dtype=torch.int32)\n",
      "tensor(0.2297, grad_fn=<MeanBackward0>)\n",
      "tensor([  5,   5,   5,   5,   5,   5,   5,   5, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 273, 273, 273, 273, 273, 273, 273, 273,  66,  66,  66,  66,\n",
      "         66,  66,  66,  66, 270, 270, 270, 270, 270, 270, 270, 270, 269, 269,\n",
      "        269, 269, 269, 269, 269, 269,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "        164, 164, 164, 164, 164, 164, 164, 164], dtype=torch.int32)\n",
      "tensor(0.6558, grad_fn=<MeanBackward0>)\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144,  77,  77,  77,  77,  77,  77,\n",
      "         77,  77, 230, 230, 230, 230, 230, 230, 230, 230, 218, 218, 218, 218,\n",
      "        218, 218, 218, 218, 198, 198, 198, 198, 198, 198, 198, 198, 169, 169,\n",
      "        169, 169, 169, 169, 169, 169,  94,  94,  94,  94,  94,  94,  94,  94,\n",
      "         28,  28,  28,  28,  28,  28,  28,  28], dtype=torch.int32)\n",
      "tensor(0.1190, grad_fn=<MeanBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d3671e5ccfba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelInter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'questions'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mquestions\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'generated_ques'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerated_ques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'bs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m64\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_save_path\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoints'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'myModel4'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\scripts\\modelInterface.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, model_save_path)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         )\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, fp16, fp16_opt_level, local_rank)\u001b[0m\n\u001b[0;32m    392\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelInter.train({'questions':questions , 'generated_ques': generated_ques, 'labels':labels , 'bs':64 ,'n':8},model_save_path =os.path.join('checkpoints', 'myModel4') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data_questions_labels_dict': data_questions_label_dict , 'test_questions_labels_dict' : test_questions_labels_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_questions_labels_dict = {test_que: data_questions_label_dict[que] for test_que, que in zip(test2_data['reframed'], test2_data['original']) if que in questions }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {'data_questions_labels_dict': data_questions_label_dict , 'test_questions_labels_dict' : test2_questions_labels_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9621993127147767"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInter.evaluate(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUG():\n",
    "    def __init__(self):\n",
    "        import nlpaug.augmenter.char as nac\n",
    "        import nlpaug.augmenter.word as naw\n",
    "        aug0 = naw.RandomWordAug()\n",
    "        aug1 = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"substitute\")\n",
    "        aug2 = naw.SynonymAug(aug_src='wordnet')\n",
    "        aug3 = naw.SplitAug()\n",
    "        aug4 = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")\n",
    "\n",
    "        self.augs = [aug0, aug1,aug2,aug3,aug4]\n",
    "        \n",
    "    def __call__(self,sent,n= 1):\n",
    "        return self.augment(sent,n)\n",
    "        \n",
    "    \n",
    "    def augment(self,sent ,n = 1):\n",
    "        import random\n",
    "        ans = []\n",
    "        sent = re.sub(r'[^a-zA-Z0-9_ ]', '', sent)\n",
    "        for _ in range(n):\n",
    "            aug = random.choice(self.augs)\n",
    "            ans.append(aug.augment(sent))\n",
    "                    \n",
    "                \n",
    "        return ans\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
