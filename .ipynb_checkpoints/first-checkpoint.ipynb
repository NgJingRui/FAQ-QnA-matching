{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn,Tensor\n",
    "from typing import Union, Tuple, List, Iterable, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf_data = pd.read_csv('./msf_baby_bonus.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json') as f:\n",
    "    generated_ques = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_answers.txt', 'r') as f:\n",
    "    test_answers = f.readlines()\n",
    "    test_answers = list(map(lambda x : x.replace('\\n',''),test_answers))\n",
    "    test_answers = list(filter(lambda x : len(x) > 0 , test_answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_questions.txt', 'r') as f:\n",
    "    test_questions = f.readlines()\n",
    "    test_questions  = list(map(lambda x : x.replace('\\n',''),test_questions))\n",
    "    test_questions  = list(filter(lambda x : len(x) > 0 , test_questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'r', encoding=\"utf8\") as f:\n",
    "    answers = f.readlines()\n",
    "    answers  = list(map(lambda x : x.replace('\\n',''),answers))\n",
    "    answers  = list(filter(lambda x : len(x) > 0 , answers))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_answers = msf_data[2].tolist()\n",
    "csv_answers = list(map(lambda x : x.replace('\\n', '').strip(),csv_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_questions = msf_data[1].tolist()\n",
    "csv_questions = list(map(lambda x : x.replace('\\n', '').strip(),csv_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    questions = []\n",
    "    labels = []\n",
    "    for q,a in zip(csv_questions , csv_answers):\n",
    "        if(a not in answers):\n",
    "            continue\n",
    "        \n",
    "        questions.append(q)\n",
    "        labels.append(answers.index(a))\n",
    "    return questions , labels\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions , labels = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from modelInterface import modelInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInter = modelInterface('./models/myModel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions_labels_dict  = {}\n",
    "data_questions_label_dict = {}\n",
    "for q,l in zip(questions, labels):\n",
    "    data_questions_label_dict[q] = l\n",
    "    gens = generated_ques[q]\n",
    "for q,l in zip(test_questions, test_answers):\n",
    "    test_questions_labels_dict[q] = l\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_to_label = {ans: i for i,ans in enumerate(answers)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInter.fit_FAQ(data_questions_label_dict, answer_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52219284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A CDA Trustee can be either the parent or a person nominated by the child’s parents.  Both parents must agree to the nomination.  He or She cannot be a bankrupt and must be above 18 years of age. The CDA trustee’s responsibility is to ensure the proper usage of CDA funds, for the benefit of the child.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInter.answer_question('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data_questions_labels_dict': data_questions_label_dict , 'test_questions_labels_dict' : test_questions_labels_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8153846153846154"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInter.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb93aa57a5246209e43d52e2d27a639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c676f41fa484ceb9449a5a266b34746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=879.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 39,  39,  39,  39,  39,  39,  39,  39,  56,  56,  56,  56,  56,  56,\n",
      "         56,  56, 198, 198, 198, 198, 198, 198, 198, 198, 287, 287, 287, 287,\n",
      "        287, 287, 287, 287], dtype=torch.int32)\n",
      "tensor(0.0823, grad_fn=<MeanBackward0>)\n",
      "tensor([ 47,  47,  47,  47,  47,  47,  47,  47, 287, 287, 287, 287, 287, 287,\n",
      "        287, 287, 196, 196, 196, 196, 196, 196, 196, 196, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120], dtype=torch.int32)\n",
      "tensor(0.0277, grad_fn=<MeanBackward0>)\n",
      "tensor([251, 251, 251, 251, 251, 251, 251, 251,  13,  13,  13,  13,  13,  13,\n",
      "         13,  13, 171, 171, 171, 171, 171, 171, 171, 171,  45,  45,  45,  45,\n",
      "         45,  45,  45,  45], dtype=torch.int32)\n",
      "tensor(0.0230, grad_fn=<MeanBackward0>)\n",
      "tensor([ 35,  35,  35,  35,  35,  35,  35,  35, 219, 219, 219, 219, 219, 219,\n",
      "        219, 219, 159, 159, 159, 159, 159, 159, 159, 159, 258, 258, 258, 258,\n",
      "        258, 258, 258, 258], dtype=torch.int32)\n",
      "tensor(0.4598, grad_fn=<MeanBackward0>)\n",
      "tensor([269, 269, 269, 269, 269, 269, 269, 269, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 282, 282, 282, 282, 282, 282, 282, 282, 234, 234, 234, 234,\n",
      "        234, 234, 234, 234], dtype=torch.int32)\n",
      "tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([ 24,  24,  24,  24,  24,  24,  24,  24,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92, 116, 116, 116, 116, 116, 116, 116, 116, 122, 122, 122, 122,\n",
      "        122, 122, 122, 122], dtype=torch.int32)\n",
      "tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([ 27,  27,  27,  27,  27,  27,  27,  27,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  23,  23,  23,  23,  23,  23,  23,  23, 193, 193, 193, 193,\n",
      "        193, 193, 193, 193], dtype=torch.int32)\n",
      "tensor(0.0364, grad_fn=<MeanBackward0>)\n",
      "tensor([217, 217, 217, 217, 217, 217, 217, 217,  33,  33,  33,  33,  33,  33,\n",
      "         33,  33, 161, 161, 161, 161, 161, 161, 161, 161, 183, 183, 183, 183,\n",
      "        183, 183, 183, 183], dtype=torch.int32)\n",
      "tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "tensor([124, 124, 124, 124, 124, 124, 124, 124, 202, 202, 202, 202, 202, 202,\n",
      "        202, 202, 118, 118, 118, 118, 118, 118, 118, 118, 278, 278, 278, 278,\n",
      "        278, 278, 278, 278], dtype=torch.int32)\n",
      "tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "tensor([196, 196, 196, 196, 196, 196, 196, 196,  23,  23,  23,  23,  23,  23,\n",
      "         23,  23, 192, 192, 192, 192, 192, 192, 192, 192, 229, 229, 229, 229,\n",
      "        229, 229, 229, 229], dtype=torch.int32)\n",
      "tensor(0.0083, grad_fn=<MeanBackward0>)\n",
      "tensor([263, 263, 263, 263, 263, 263, 263, 263,  80,  80,  80,  80,  80,  80,\n",
      "         80,  80, 191, 191, 191, 191, 191, 191, 191, 191,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91], dtype=torch.int32)\n",
      "tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "tensor([285, 285, 285, 285, 285, 285, 285, 285, 207, 207, 207, 207, 207, 207,\n",
      "        207, 207,  65,  65,  65,  65,  65,  65,  65,  65, 211, 211, 211, 211,\n",
      "        211, 211, 211, 211], dtype=torch.int32)\n",
      "tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "tensor([ 55,  55,  55,  55,  55,  55,  55,  55,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82,  12,  12,  12,  12,  12,  12,  12,  12, 250, 250, 250, 250,\n",
      "        250, 250, 250, 250], dtype=torch.int32)\n",
      "tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "tensor([32, 32, 32, 32, 32, 32, 32, 32, 91, 91, 91, 91, 91, 91, 91, 91,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2, 83, 83, 83, 83, 83, 83, 83, 83],\n",
      "       dtype=torch.int32)\n",
      "tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "tensor([ 73,  73,  73,  73,  73,  73,  73,  73, 215, 215, 215, 215, 215, 215,\n",
      "        215, 215, 244, 244, 244, 244, 244, 244, 244, 244, 257, 257, 257, 257,\n",
      "        257, 257, 257, 257], dtype=torch.int32)\n",
      "tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "tensor([268, 268, 268, 268, 268, 268, 268, 268,  64,  64,  64,  64,  64,  64,\n",
      "         64,  64, 174, 174, 174, 174, 174, 174, 174, 174, 193, 193, 193, 193,\n",
      "        193, 193, 193, 193], dtype=torch.int32)\n",
      "tensor(0.2023, grad_fn=<MeanBackward0>)\n",
      "tensor([119, 119, 119, 119, 119, 119, 119, 119, 153, 153, 153, 153, 153, 153,\n",
      "        153, 153,  64,  64,  64,  64,  64,  64,  64,  64,  78,  78,  78,  78,\n",
      "         78,  78,  78,  78], dtype=torch.int32)\n",
      "tensor(0.0255, grad_fn=<MeanBackward0>)\n",
      "tensor([241, 241, 241, 241, 241, 241, 241, 241, 137, 137, 137, 137, 137, 137,\n",
      "        137, 137,  44,  44,  44,  44,  44,  44,  44,  44, 102, 102, 102, 102,\n",
      "        102, 102, 102, 102], dtype=torch.int32)\n",
      "tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "tensor([194, 194, 194, 194, 194, 194, 194, 194,  15,  15,  15,  15,  15,  15,\n",
      "         15,  15, 132, 132, 132, 132, 132, 132, 132, 132, 149, 149, 149, 149,\n",
      "        149, 149, 149, 149], dtype=torch.int32)\n",
      "tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "tensor([283, 283, 283, 283, 283, 283, 283, 283,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 272, 272, 272, 272, 272, 272, 272, 272,  72,  72,  72,  72,\n",
      "         72,  72,  72,  72], dtype=torch.int32)\n",
      "tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([ 21,  21,  21,  21,  21,  21,  21,  21, 135, 135, 135, 135, 135, 135,\n",
      "        135, 135, 138, 138, 138, 138, 138, 138, 138, 138, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134], dtype=torch.int32)\n",
      "tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "tensor([ 70,  70,  70,  70,  70,  70,  70,  70,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 218, 218, 218, 218, 218, 218, 218, 218,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27], dtype=torch.int32)\n",
      "tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "tensor([ 89,  89,  89,  89,  89,  89,  89,  89,   4,   4,   4,   4,   4,   4,\n",
      "          4,   4, 257, 257, 257, 257, 257, 257, 257, 257, 236, 236, 236, 236,\n",
      "        236, 236, 236, 236], dtype=torch.int32)\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([141, 141, 141, 141, 141, 141, 141, 141,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,  59,  59,  59,  59,  59,  59,  59,  59, 106, 106, 106, 106,\n",
      "        106, 106, 106, 106], dtype=torch.int32)\n",
      "tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([41, 41, 41, 41, 41, 41, 41, 41, 99, 99, 99, 99, 99, 99, 99, 99, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 50, 50, 50, 50, 50, 50, 50, 50],\n",
      "       dtype=torch.int32)\n",
      "tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "tensor([155, 155, 155, 155, 155, 155, 155, 155, 257, 257, 257, 257, 257, 257,\n",
      "        257, 257, 178, 178, 178, 178, 178, 178, 178, 178,  89,  89,  89,  89,\n",
      "         89,  89,  89,  89], dtype=torch.int32)\n",
      "tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "tensor([ 17,  17,  17,  17,  17,  17,  17,  17, 180, 180, 180, 180, 180, 180,\n",
      "        180, 180, 115, 115, 115, 115, 115, 115, 115, 115, 246, 246, 246, 246,\n",
      "        246, 246, 246, 246], dtype=torch.int32)\n",
      "tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([259, 259, 259, 259, 259, 259, 259, 259, 184, 184, 184, 184, 184, 184,\n",
      "        184, 184, 148, 148, 148, 148, 148, 148, 148, 148, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103], dtype=torch.int32)\n",
      "tensor(0.0039, grad_fn=<MeanBackward0>)\n",
      "tensor([ 24,  24,  24,  24,  24,  24,  24,  24, 104, 104, 104, 104, 104, 104,\n",
      "        104, 104, 281, 281, 281, 281, 281, 281, 281, 281, 191, 191, 191, 191,\n",
      "        191, 191, 191, 191], dtype=torch.int32)\n",
      "tensor(0.0049, grad_fn=<MeanBackward0>)\n",
      "tensor([165, 165, 165, 165, 165, 165, 165, 165, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 251, 251, 251, 251, 251, 251, 251, 251, 289, 289, 289, 289,\n",
      "        289, 289, 289, 289], dtype=torch.int32)\n",
      "tensor(0.0062, grad_fn=<MeanBackward0>)\n",
      "tensor([ 35,  35,  35,  35,  35,  35,  35,  35,  63,  63,  63,  63,  63,  63,\n",
      "         63,  63, 235, 235, 235, 235, 235, 235, 235, 235, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166], dtype=torch.int32)\n",
      "tensor(3.7361e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([182, 182, 182, 182, 182, 182, 182, 182,  67,  67,  67,  67,  67,  67,\n",
      "         67,  67, 236, 236, 236, 236, 236, 236, 236, 236,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25], dtype=torch.int32)\n",
      "tensor(0.0097, grad_fn=<MeanBackward0>)\n",
      "tensor([174, 174, 174, 174, 174, 174, 174, 174,  41,  41,  41,  41,  41,  41,\n",
      "         41,  41,  86,  86,  86,  86,  86,  86,  86,  86, 194, 194, 194, 194,\n",
      "        194, 194, 194, 194], dtype=torch.int32)\n",
      "tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([105, 105, 105, 105, 105, 105, 105, 105, 242, 242, 242, 242, 242, 242,\n",
      "        242, 242, 213, 213, 213, 213, 213, 213, 213, 213, 169, 169, 169, 169,\n",
      "        169, 169, 169, 169], dtype=torch.int32)\n",
      "tensor(0.0172, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([102, 102, 102, 102, 102, 102, 102, 102, 202, 202, 202, 202, 202, 202,\n",
      "        202, 202, 241, 241, 241, 241, 241, 241, 241, 241, 279, 279, 279, 279,\n",
      "        279, 279, 279, 279], dtype=torch.int32)\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([ 31,  31,  31,  31,  31,  31,  31,  31,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38, 241, 241, 241, 241, 241, 241, 241, 241,  39,  39,  39,  39,\n",
      "         39,  39,  39,  39], dtype=torch.int32)\n",
      "tensor(0.0069, grad_fn=<MeanBackward0>)\n",
      "tensor([107, 107, 107, 107, 107, 107, 107, 107, 214, 214, 214, 214, 214, 214,\n",
      "        214, 214,  30,  30,  30,  30,  30,  30,  30,  30, 290, 290, 290, 290,\n",
      "        290, 290, 290, 290], dtype=torch.int32)\n",
      "tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([105, 105, 105, 105, 105, 105, 105, 105,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  44,  44,  44,  44,  44,  44,  44,  44, 152, 152, 152, 152,\n",
      "        152, 152, 152, 152], dtype=torch.int32)\n",
      "tensor(0.0137, grad_fn=<MeanBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c77348d4bd26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelInter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'questions'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mquestions\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'generated_ques'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerated_ques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'bs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_save_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'models/myModelTest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\scripts\\modelInterface.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, model_save_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         )\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, fp16, fp16_opt_level, local_rank)\u001b[0m\n\u001b[0;32m    393\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;34mr\"\"\"See :func:`torch.norm`\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"nuc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fro\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelInter.train({'questions':questions , 'generated_ques': generated_ques, 'labels':labels , 'bs':32 ,'n':4},model_save_path = 'models/myModelTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeds = model.encode(questions)\n",
    "q_embeds = np.array(q_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq_embeds = model.encode(test_questions)\n",
    "tq_embeds = np.array(tq_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign():\n",
    "    n1 = np.linalg.norm(tq_embeds, axis = -1)\n",
    "    n2 = np.linalg.norm(q_embeds, axis = -1)\n",
    "    dot = np.expand_dims(tq_embeds , 1)*np.expand_dims(q_embeds,0)\n",
    "    dot = dot.sum(axis = -1)\n",
    "    ans = dot/n1.reshape(-1,1)\n",
    "    ans = ans/n2.reshape(1,-1)\n",
    "    return np.argmax(ans , axis = -1), ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned, ans = assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78735375, 0.91230446, 0.753919  , 0.7258304 , 0.927165  ,\n",
       "       0.88282144, 0.7784794 , 0.8124629 , 0.7006926 , 0.82574904,\n",
       "       0.7039604 , 0.7765373 , 0.76268244, 0.95239997, 0.87162924,\n",
       "       0.8413708 , 0.67673886, 0.81089014, 0.88396907, 0.73399264,\n",
       "       0.89649147, 0.9287177 , 0.5353112 , 0.84976786, 0.7745759 ,\n",
       "       0.7890316 , 0.9600214 , 0.8691442 , 0.92594224, 0.618693  ,\n",
       "       0.62028974, 0.9433868 , 0.9246678 , 0.7870786 , 0.70038885,\n",
       "       0.82204586, 0.6064853 , 0.8051151 , 0.9084486 , 0.8684028 ,\n",
       "       0.894618  , 0.91790235, 0.85900104, 0.93909425, 0.83968264,\n",
       "       0.9285271 , 0.8024838 , 0.9415216 , 0.9591521 , 0.5772507 ,\n",
       "       0.9115484 , 0.87189823, 0.9377835 , 0.82952034, 0.8774469 ,\n",
       "       0.9378167 , 0.8123381 , 0.717871  , 0.96868825, 0.9235323 ,\n",
       "       0.85285187, 0.9478283 , 0.8404879 , 0.9742791 , 0.92760664,\n",
       "       0.9801053 , 0.97454864, 0.93405783, 0.8453288 , 0.7521198 ,\n",
       "       0.86125225, 0.8883487 , 0.9417546 , 0.758313  , 0.934008  ,\n",
       "       0.9236708 , 0.9189825 , 0.94742745, 0.9629319 , 0.84534574,\n",
       "       0.769981  , 0.9338387 , 0.94608206, 0.9029584 , 0.8328997 ,\n",
       "       0.95469975, 0.91487575, 0.88750046, 0.9135992 , 0.8571373 ,\n",
       "       0.94827765, 0.9246306 , 0.81133986, 0.8110406 , 0.92573327,\n",
       "       0.9253352 , 0.92812324, 0.9474383 , 0.9416302 , 0.85518163,\n",
       "       0.8417295 , 0.7267629 , 0.6400673 , 0.86788017, 0.6826208 ,\n",
       "       0.5783895 , 0.7202238 , 0.84775877, 0.54805243, 0.8880069 ,\n",
       "       0.8331388 , 0.8187399 , 0.9020683 , 0.86628175, 0.7460359 ,\n",
       "       0.7327923 , 0.8864868 , 0.85834455, 0.92321056, 0.84940046,\n",
       "       0.44422072, 0.7325304 , 0.49995255, 0.6961615 , 0.33981615,\n",
       "       0.7700047 , 0.7061469 , 0.79019576, 0.36358422, 0.43258047],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.max(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 127, 226, 176,  98, 178, 234,  48, 167,  59, 176, 290, 292,\n",
       "         6,  62, 115, 104, 180, 196,  76, 230, 266, 130, 179, 186,  61,\n",
       "       208, 288, 235, 257, 183,  96,  83,  46,  27,   8,  95,  99,  71,\n",
       "        31,  15, 124, 169, 171, 264, 205, 276, 204, 284,   5, 124,   6,\n",
       "         8,  12,  18,  20,  21,  25,  30,  32,  42,  44,  48,  47,  49,\n",
       "        50,  57,  60,  62,  68,  44,  73,  76,  72,  83,  84,  87,  89,\n",
       "        88,  88,  92,  93,  96,  97, 100, 101, 102,  29, 114, 118, 119,\n",
       "       121, 123, 114, 126,  70, 132, 136, 138, 141,   5,  96,  27,  62,\n",
       "        84, 203, 182, 222, 257, 286, 127, 123, 134, 141, 290, 187, 100,\n",
       "        51,  59, 130, 240, 265,  34, 290,  84, 115, 137,  60, 104,  52],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 127, 226, 176,  98, 178, 234,  48, 167,  59, 176, 290, 292,\n",
       "         6,  62, 115, 104, 180, 196,  76, 230, 266, 130, 179, 186,  61,\n",
       "       208, 288, 235, 257, 183,  96,  83,  46,  27,   8,  95,  99,  71,\n",
       "        31,  15, 124, 169, 171, 264, 205, 276, 204, 284,   5, 124,   6,\n",
       "         8,  12,  18,  20,  21,  25,  30,  32,  42,  44,  48,  47,  49,\n",
       "        50,  57,  60,  62,  68,  44,  73,  76,  72,  83,  84,  87,  89,\n",
       "        88,  88,  92,  93,  96,  97, 100, 101, 102,  29, 114, 118, 119,\n",
       "       121, 123, 114, 126,  70, 132, 136, 138, 141,   5,  96,  27,  62,\n",
       "        84, 203, 182, 222, 257, 286, 127, 123, 134, 141, 290, 187, 100,\n",
       "        51,  59, 130, 240, 265,  34, 290,  84, 115, 137,  60, 104,  52],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tars = np.array(test_answers).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.15384615384615"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((tars == assigned).sum()/130)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "\n",
    "\n",
    "class InputExample:\n",
    "    \"\"\"\n",
    "    Structure for one input example with texts, the label and a unique id\n",
    "    \"\"\"\n",
    "    def __init__(self, guid: str, texts: List[str], label: Union[int, float]):\n",
    "        \"\"\"\n",
    "        Creates one InputExample with the given texts, guid and label\n",
    "        str.strip() is called on both texts.\n",
    "        :param guid\n",
    "            id for the example\n",
    "        :param texts\n",
    "            the texts for the example\n",
    "        :param label\n",
    "            the label for the example\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.texts = [text.strip() for text in texts]\n",
    "        self.label = label\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<InputExample> label: {}, texts: {}\".format(str(self.label), \"; \".join(self.texts))\n",
    "\n",
    "\n",
    "class Question_sampler(Dataset): \n",
    "    def __init__(self,questions,generated_ques,model,labels = None, bs = 32 , n = 4):\n",
    "        \"\"\"\n",
    "        questions --> array of string\n",
    "        labels --> array of labels\n",
    "        generated_ques --> a dict from ques to array of generated ques\n",
    "        bs --> batch size\n",
    "        n  --> number of classes to pick , from \n",
    "        \"\"\"\n",
    "       \n",
    "        self.questions = questions\n",
    "        if(labels is None):\n",
    "            labels = [x for x in range(len(questions))]\n",
    "            \n",
    "        assert len(questions) == len(labels), 'length of ques is {} but len of labels is {}'.format(len(questions), len(labels))\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.model = model\n",
    "        self.data = {}\n",
    "        # data is a dict from label to array of questions\n",
    "        self.min_gen = 100000000000\n",
    "        self.classes = len(set(self.labels))\n",
    "        for i,que in enumerate(questions):\n",
    "            self.min_gen = min(self.min_gen , len(generated_ques[que]))\n",
    "            if(self.labels[i] not in self.data):\n",
    "                self.data[self.labels[i]] = []\n",
    "            self.data[self.labels[i]] += [que] + generated_ques[que]\n",
    "             \n",
    "        self.sequence = []\n",
    "        self.make_sequence(total_examples = len(questions)*3, batch_size = bs,n = n)\n",
    "    def __len__(self):\n",
    "        return len(self.sequence[0])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inp , lab = self.sequence\n",
    "        return [inp[index]], lab[index]\n",
    "    def sample_triplet(self):\n",
    "        \"\"\"\n",
    "        To sample triplet from a sentence\n",
    "        returns a pair of triplet\n",
    "        [Anchor , positive , negative]\n",
    "        \"\"\"\n",
    "        total_ques = len(self.questions)\n",
    "        anchor_data_index,neg_data_index = np.random.choice(len(self.data), size = 2,replace = False).tolist()\n",
    "        pos_list = self.data[anchor_data_index]\n",
    "        anchor_index , pos_index = np.random.choice(len(pos_list), size = 2,replace = False).tolist()\n",
    "        anchor , pos = pos_list[anchor_index].strip() , pos_list[pos_index].strip() \n",
    "        neg_list = self.data[neg_data_index]\n",
    "        neg_index = np.random.choice(len(neg_list))\n",
    "        neg = neg_list[neg_index]\n",
    "        \n",
    "        \n",
    "        return [anchor, pos, neg]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def make_sequence_util(self, n , k):\n",
    "        \"\"\"\n",
    "        to make a batch of n classes\n",
    "        where each class has k examples\n",
    "        \"\"\"\n",
    "        if(n <= self.classes):\n",
    "            class_indices = np.random.choice(self.labels , size = n , replace = False)\n",
    "        else:\n",
    "            warnings.warn('n is greater than number of classes') \n",
    "            class_indices = np.random.choice(self.labels , size = n , replace = True)\n",
    "        \n",
    "        \n",
    "        batch_inps = []\n",
    "        batch_labels = []\n",
    "        for i in class_indices:\n",
    "            label = i\n",
    "            ques = self.data[i]\n",
    "            num_ques = len(ques)\n",
    "            if(k <= num_ques):\n",
    "                que_indices = np.random.choice(num_ques, size = k, replace = False)\n",
    "            else:\n",
    "                warnings.warn('k is greater than than number of generated ques')\n",
    "                que_indices = np.random.choice(num_ques, size = k, replace = True)\n",
    "                \n",
    "            for j in que_indices:\n",
    "                batch_inps.append(self.model.tokenize(ques[j]))\n",
    "                batch_labels.append(label)\n",
    "        return [batch_inps, batch_labels]\n",
    "            \n",
    "    def make_sequence(self,total_examples,batch_size,n):\n",
    "        \"\"\"\n",
    "        total_examples number of batches are formed --> making the seq batch_size*total_examples long\n",
    "        n  class are drawn in each batch \n",
    "        batch_size//n number of examples for each classes\n",
    "        \"\"\"\n",
    "        assert batch_size%n == 0 , 'batch_size should be divisible by n'\n",
    "        self.sequence = []\n",
    "        batch_inps = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for i in range(total_examples):\n",
    "            x,y = self.make_sequence_util(n,batch_size//n)\n",
    "            # sampled a batch , of size batch_size\n",
    "            batch_inps += x\n",
    "            batch_labels += y\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.sequence = [batch_inps, torch.tensor(batch_labels)]\n",
    "        \n",
    "        \n",
    "def get_dataloader(self,questions,generated_ques,model,labels = None, bs = 32 , n = 4):\n",
    "    \"\"\"\n",
    "        questions --> array of string\n",
    "        labels --> array of labels\n",
    "        generated_ques --> a dict from ques to array of generated ques\n",
    "        bs --> batch size\n",
    "        n  --> number of classes to pick , from \n",
    "    \"\"\"\n",
    "\n",
    "    Q = Question_sampler(questions ,generated_ques,model,labels)\n",
    "    train_data = Q\n",
    "    train_dataloader = DataLoader(train_data,  batch_size= 32, sampler= SequentialSampler(train_data))\n",
    "    return train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.datasets import SentenceLabelDataset\n",
    "from sentence_transformers.data_samplers import LabelSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Question_sampler(questions ,generated_ques,modelInter.model,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[118,\n",
       "   33,\n",
       "   682,\n",
       "   4813,\n",
       "   10,\n",
       "   2069,\n",
       "   13,\n",
       "   464,\n",
       "   9,\n",
       "   920,\n",
       "   709,\n",
       "   15756,\n",
       "   740,\n",
       "   6106,\n",
       "   19467,\n",
       "   804,\n",
       "   141,\n",
       "   109,\n",
       "   939,\n",
       "   216,\n",
       "   5,\n",
       "   1881,\n",
       "   9,\n",
       "   5,\n",
       "   464]],\n",
       " tensor(192, dtype=torch.int32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_data = Q\n",
    "train_dataloader = DataLoader(train_data,  batch_size= 32, sampler= SequentialSampler(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([192, 192, 192, 192, 192, 192, 192, 192, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 290, 290, 290, 290, 290, 290, 290, 290, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    _, label = data\n",
    "    print(label)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluator = TripletEvaluator(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.BatchHardTripletLoss(sentence_embedder=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_save_path = 'output/training_stsbenchmark_continue_training-'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_save_path = 'models/myModel3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391a20fd3326412db278bf037a1070ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca45f18ffa14bffb39310939c977df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1758.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([166, 166, 166, 166,  97,  97,  97,  97, 186, 186, 186, 186, 228, 228,\n",
      "        228, 228])\n",
      "tensor(0.0157, grad_fn=<MeanBackward0>)\n",
      "tensor([ 19,  19,  19,  19, 256, 256, 256, 256, 226, 226, 226, 226, 273, 273,\n",
      "        273, 273])\n",
      "tensor(0.0072, grad_fn=<MeanBackward0>)\n",
      "tensor([286, 286, 286, 286, 262, 262, 262, 262,  41,  41,  41,  41, 279, 279,\n",
      "        279, 279])\n",
      "tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "tensor([188, 188, 188, 188, 197, 197, 197, 197, 252, 252, 252, 252, 127, 127,\n",
      "        127, 127])\n",
      "tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "tensor([271, 271, 271, 271, 115, 115, 115, 115, 171, 171, 171, 171, 102, 102,\n",
      "        102, 102])\n",
      "tensor(9.3992e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([118, 118, 118, 118, 117, 117, 117, 117, 166, 166, 166, 166,  58,  58,\n",
      "         58,  58])\n",
      "tensor(0.6323, grad_fn=<MeanBackward0>)\n",
      "tensor([239, 239, 239, 239,  45,  45,  45,  45,  28,  28,  28,  28,  18,  18,\n",
      "         18,  18])\n",
      "tensor(0.0188, grad_fn=<MeanBackward0>)\n",
      "tensor([225, 225, 225, 225, 199, 199, 199, 199, 129, 129, 129, 129, 228, 228,\n",
      "        228, 228])\n",
      "tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "tensor([100, 100, 100, 100, 236, 236, 236, 236, 252, 252, 252, 252, 240, 240,\n",
      "        240, 240])\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([  5,   5,   5,   5, 220, 220, 220, 220,  16,  16,  16,  16,  48,  48,\n",
      "         48,  48])\n",
      "tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "tensor([ 68,  68,  68,  68,   8,   8,   8,   8, 263, 263, 263, 263, 276, 276,\n",
      "        276, 276])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([117, 117, 117, 117, 147, 147, 147, 147,  39,  39,  39,  39, 186, 186,\n",
      "        186, 186])\n",
      "tensor(6.9730e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([ 24,  24,  24,  24, 282, 282, 282, 282,  15,  15,  15,  15, 240, 240,\n",
      "        240, 240])\n",
      "tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "tensor([258, 258, 258, 258,  61,  61,  61,  61, 229, 229, 229, 229, 280, 280,\n",
      "        280, 280])\n",
      "tensor(8.4536e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([126, 126, 126, 126,  65,  65,  65,  65, 204, 204, 204, 204, 286, 286,\n",
      "        286, 286])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 66,  66,  66,  66, 229, 229, 229, 229,  56,  56,  56,  56, 131, 131,\n",
      "        131, 131])\n",
      "tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([215, 215, 215, 215, 226, 226, 226, 226,   6,   6,   6,   6, 136, 136,\n",
      "        136, 136])\n",
      "tensor(0.0141, grad_fn=<MeanBackward0>)\n",
      "tensor([259, 259, 259, 259, 251, 251, 251, 251,  76,  76,  76,  76, 121, 121,\n",
      "        121, 121])\n",
      "tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([290, 290, 290, 290,  70,  70,  70,  70, 228, 228, 228, 228, 181, 181,\n",
      "        181, 181])\n",
      "tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "tensor([ 56,  56,  56,  56, 144, 144, 144, 144, 215, 215, 215, 215,  90,  90,\n",
      "         90,  90])\n",
      "tensor(3.8179e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([162, 162, 162, 162, 289, 289, 289, 289, 233, 233, 233, 233,  81,  81,\n",
      "         81,  81])\n",
      "tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([202, 202, 202, 202,  46,  46,  46,  46, 210, 210, 210, 210, 277, 277,\n",
      "        277, 277])\n",
      "tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "tensor([204, 204, 204, 204,  29,  29,  29,  29,  85,  85,  85,  85,  67,  67,\n",
      "         67,  67])\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([ 64,  64,  64,  64, 223, 223, 223, 223, 149, 149, 149, 149, 136, 136,\n",
      "        136, 136])\n",
      "tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([185, 185, 185, 185,  71,  71,  71,  71, 223, 223, 223, 223, 121, 121,\n",
      "        121, 121])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 88,  88,  88,  88,  50,  50,  50,  50,  62,  62,  62,  62, 202, 202,\n",
      "        202, 202])\n",
      "tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([170, 170, 170, 170,  71,  71,  71,  71, 242, 242, 242, 242,  60,  60,\n",
      "         60,  60])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 86,  86,  86,  86,  91,  91,  91,  91, 168, 168, 168, 168, 241, 241,\n",
      "        241, 241])\n",
      "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor([189, 189, 189, 189, 144, 144, 144, 144,  83,  83,  83,  83, 236, 236,\n",
      "        236, 236])\n",
      "tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "tensor([158, 158, 158, 158, 247, 247, 247, 247, 163, 163, 163, 163, 258, 258,\n",
      "        258, 258])\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([157, 157, 157, 157, 156, 156, 156, 156,   7,   7,   7,   7, 276, 276,\n",
      "        276, 276])\n",
      "tensor(4.2438e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([ 14,  14,  14,  14, 173, 173, 173, 173, 154, 154, 154, 154, 179, 179,\n",
      "        179, 179])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 22,  22,  22,  22,  45,  45,  45,  45,  92,  92,  92,  92, 254, 254,\n",
      "        254, 254])\n",
      "tensor(0.0073, grad_fn=<MeanBackward0>)\n",
      "tensor([238, 238, 238, 238, 174, 174, 174, 174, 266, 266, 266, 266, 202, 202,\n",
      "        202, 202])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 33,  33,  33,  33,  59,  59,  59,  59, 247, 247, 247, 247, 238, 238,\n",
      "        238, 238])\n",
      "tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "tensor([ 90,  90,  90,  90, 176, 176, 176, 176,  85,  85,  85,  85,  84,  84,\n",
      "         84,  84])\n",
      "tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "tensor([275, 275, 275, 275,  49,  49,  49,  49,  83,  83,  83,  83,  42,  42,\n",
      "         42,  42])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 39,  39,  39,  39, 255, 255, 255, 255, 134, 134, 134, 134, 272, 272,\n",
      "        272, 272])\n",
      "tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "tensor([249, 249, 249, 249, 140, 140, 140, 140, 283, 283, 283, 283, 155, 155,\n",
      "        155, 155])\n",
      "tensor(7.3732e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([151, 151, 151, 151, 146, 146, 146, 146, 255, 255, 255, 255, 185, 185,\n",
      "        185, 185])\n",
      "tensor(0.0134, grad_fn=<MeanBackward0>)\n",
      "tensor([ 92,  92,  92,  92,  39,  39,  39,  39, 169, 169, 169, 169, 211, 211,\n",
      "        211, 211])\n",
      "tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "tensor([ 77,  77,  77,  77, 267, 267, 267, 267, 159, 159, 159, 159,  32,  32,\n",
      "         32,  32])\n",
      "tensor(2.0295e-05, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    evaluator = None,\n",
    "    output_path= model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/myModel3\\\\modules.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-50598dbdc233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[0;32m     73\u001b[0m                             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__version__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'modules.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfIn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m                     \u001b[0mcontained_modules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfIn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/myModel3\\\\modules.json'"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/myModel2'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
