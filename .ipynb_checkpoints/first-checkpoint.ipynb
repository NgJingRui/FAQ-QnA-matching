{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn,Tensor\n",
    "from typing import Union, Tuple, List, Iterable, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf_data = pd.read_csv('./msf_baby_bonus.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_data = pd.read_csv('./aprilfinal.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json') as f:\n",
    "    generated_ques = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_answers.txt', 'r') as f:\n",
    "    test_answers = f.readlines()\n",
    "    test_answers = list(map(lambda x : x.replace('\\n',''),test_answers))\n",
    "    test_answers = list(filter(lambda x : len(x) > 0 , test_answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_questions.txt', 'r') as f:\n",
    "    test_questions = f.readlines()\n",
    "    test_questions  = list(map(lambda x : x.replace('\\n',''),test_questions))\n",
    "    test_questions  = list(filter(lambda x : len(x) > 0 , test_questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'r', encoding=\"utf8\") as f:\n",
    "    answers = f.readlines()\n",
    "    answers  = list(map(lambda x : x.replace('\\n',''),answers))\n",
    "    answers  = list(filter(lambda x : len(x) > 0 , answers))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_answers = msf_data[2].tolist()\n",
    "csv_answers = list(map(lambda x : x.replace('\\n', '').strip(),csv_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_questions = msf_data[1].tolist()\n",
    "csv_questions = list(map(lambda x : x.replace('\\n', '').strip(),csv_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    questions = []\n",
    "    labels = []\n",
    "    for q,a in zip(csv_questions , csv_answers):\n",
    "        if(a not in answers):\n",
    "            continue\n",
    "        \n",
    "        questions.append(q)\n",
    "        labels.append(answers.index(a))\n",
    "    return questions , labels\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions , labels = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts')\n",
    "sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from modelInterface import modelInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInter = modelInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions_labels_dict  = {}\n",
    "data_questions_label_dict = {}\n",
    "for q,l in zip(questions, labels):\n",
    "    data_questions_label_dict[q] = l\n",
    "    gens = generated_ques[q]\n",
    "for q,l in zip(test_questions, test_answers):\n",
    "    test_questions_labels_dict[q] = l\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_to_label = {ans: i for i,ans in enumerate(answers)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./scripts\\modelInterface.py:172: UserWarning: some labels in answers are not present in questions , you might not have labels in Sync\n",
      "  warnings.warn('some labels in answers are not present in questions , you might not have labels in Sync')\n"
     ]
    }
   ],
   "source": [
    "modelInter.fit_FAQ(data_questions_label_dict, answer_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28464416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Medisave Grant for Newborns is a grant to help parents defray their child’s healthcare expenses such as MediShield Life premiums, recommended childhood vaccinations, hospitalisations, and approved outpatient treatments. It is administered by the Central Provident Fund Board (CPF). To find out more, please visit the Hey Baby website.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInter.answer_question('hello ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f8843d674b4be59e9088fc6a840ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8714e3ff2d904f62ba7e9c1461ad8e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=293.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([198, 198, 198, 198, 198, 198, 198, 198, 184, 184, 184, 184, 184, 184,\n",
      "        184, 184,  48,  48,  48,  48,  48,  48,  48,  48, 206, 206, 206, 206,\n",
      "        206, 206, 206, 206,  97,  97,  97,  97,  97,  97,  97,  97, 107, 107,\n",
      "        107, 107, 107, 107, 107, 107,  33,  33,  33,  33,  33,  33,  33,  33,\n",
      "        124, 124, 124, 124, 124, 124, 124, 124], dtype=torch.int32)\n",
      "tensor(1.1054, grad_fn=<MeanBackward0>)\n",
      "tensor([175, 175, 175, 175, 175, 175, 175, 175,  39,  39,  39,  39,  39,  39,\n",
      "         39,  39, 255, 255, 255, 255, 255, 255, 255, 255,  78,  78,  78,  78,\n",
      "         78,  78,  78,  78,  88,  88,  88,  88,  88,  88,  88,  88, 258, 258,\n",
      "        258, 258, 258, 258, 258, 258,  64,  64,  64,  64,  64,  64,  64,  64,\n",
      "         21,  21,  21,  21,  21,  21,  21,  21], dtype=torch.int32)\n",
      "tensor(0.4469, grad_fn=<MeanBackward0>)\n",
      "tensor([156, 156, 156, 156, 156, 156, 156, 156, 224, 224, 224, 224, 224, 224,\n",
      "        224, 224, 154, 154, 154, 154, 154, 154, 154, 154, 178, 178, 178, 178,\n",
      "        178, 178, 178, 178,  69,  69,  69,  69,  69,  69,  69,  69,  20,  20,\n",
      "         20,  20,  20,  20,  20,  20, 119, 119, 119, 119, 119, 119, 119, 119,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196], dtype=torch.int32)\n",
      "tensor(0.6684, grad_fn=<MeanBackward0>)\n",
      "tensor([132, 132, 132, 132, 132, 132, 132, 132, 279, 279, 279, 279, 279, 279,\n",
      "        279, 279, 247, 247, 247, 247, 247, 247, 247, 247, 119, 119, 119, 119,\n",
      "        119, 119, 119, 119, 240, 240, 240, 240, 240, 240, 240, 240, 222, 222,\n",
      "        222, 222, 222, 222, 222, 222, 176, 176, 176, 176, 176, 176, 176, 176,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133], dtype=torch.int32)\n",
      "tensor(0.3487, grad_fn=<MeanBackward0>)\n",
      "tensor([ 89,  89,  89,  89,  89,  89,  89,  89, 203, 203, 203, 203, 203, 203,\n",
      "        203, 203,  50,  50,  50,  50,  50,  50,  50,  50, 238, 238, 238, 238,\n",
      "        238, 238, 238, 238, 239, 239, 239, 239, 239, 239, 239, 239,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,  47,  47,  47,  47,  47,  47,  47,  47,\n",
      "        170, 170, 170, 170, 170, 170, 170, 170], dtype=torch.int32)\n",
      "tensor(1.1174, grad_fn=<MeanBackward0>)\n",
      "tensor([175, 175, 175, 175, 175, 175, 175, 175, 278, 278, 278, 278, 278, 278,\n",
      "        278, 278,   9,   9,   9,   9,   9,   9,   9,   9,  39,  39,  39,  39,\n",
      "         39,  39,  39,  39, 225, 225, 225, 225, 225, 225, 225, 225,  74,  74,\n",
      "         74,  74,  74,  74,  74,  74, 156, 156, 156, 156, 156, 156, 156, 156,\n",
      "         67,  67,  67,  67,  67,  67,  67,  67], dtype=torch.int32)\n",
      "tensor(0.2026, grad_fn=<MeanBackward0>)\n",
      "tensor([ 50,  50,  50,  50,  50,  50,  50,  50,  85,  85,  85,  85,  85,  85,\n",
      "         85,  85, 226, 226, 226, 226, 226, 226, 226, 226, 209, 209, 209, 209,\n",
      "        209, 209, 209, 209, 138, 138, 138, 138, 138, 138, 138, 138, 136, 136,\n",
      "        136, 136, 136, 136, 136, 136, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127], dtype=torch.int32)\n",
      "tensor(0.7514, grad_fn=<MeanBackward0>)\n",
      "tensor([  3,   3,   3,   3,   3,   3,   3,   3, 233, 233, 233, 233, 233, 233,\n",
      "        233, 233, 158, 158, 158, 158, 158, 158, 158, 158, 198, 198, 198, 198,\n",
      "        198, 198, 198, 198,  68,  68,  68,  68,  68,  68,  68,  68,  14,  14,\n",
      "         14,  14,  14,  14,  14,  14, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        256, 256, 256, 256, 256, 256, 256, 256], dtype=torch.int32)\n",
      "tensor(0.4718, grad_fn=<MeanBackward0>)\n",
      "tensor([ 96,  96,  96,  96,  96,  96,  96,  96, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149,  90,  90,  90,  90,  90,  90,  90,  90,  70,  70,  70,  70,\n",
      "         70,  70,  70,  70, 277, 277, 277, 277, 277, 277, 277, 277, 135, 135,\n",
      "        135, 135, 135, 135, 135, 135, 189, 189, 189, 189, 189, 189, 189, 189,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128], dtype=torch.int32)\n",
      "tensor(1.3636, grad_fn=<MeanBackward0>)\n",
      "tensor([285, 285, 285, 285, 285, 285, 285, 285,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  44,  44,  44,  44,  44,  44,  44,  44,  34,  34,  34,  34,\n",
      "         34,  34,  34,  34, 107, 107, 107, 107, 107, 107, 107, 107, 133, 133,\n",
      "        133, 133, 133, 133, 133, 133, 249, 249, 249, 249, 249, 249, 249, 249,\n",
      "        249, 249, 249, 249, 249, 249, 249, 249], dtype=torch.int32)\n",
      "tensor(0.5593, grad_fn=<MeanBackward0>)\n",
      "tensor([248, 248, 248, 248, 248, 248, 248, 248, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 225, 225, 225, 225, 225, 225, 225, 225, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186,   5,   5,   5,   5,   5,   5,   5,   5, 168, 168,\n",
      "        168, 168, 168, 168, 168, 168, 163, 163, 163, 163, 163, 163, 163, 163,\n",
      "        253, 253, 253, 253, 253, 253, 253, 253], dtype=torch.int32)\n",
      "tensor(1.0698, grad_fn=<MeanBackward0>)\n",
      "tensor([283, 283, 283, 283, 283, 283, 283, 283,  48,  48,  48,  48,  48,  48,\n",
      "         48,  48, 166, 166, 166, 166, 166, 166, 166, 166, 194, 194, 194, 194,\n",
      "        194, 194, 194, 194,  42,  42,  42,  42,  42,  42,  42,  42, 180, 180,\n",
      "        180, 180, 180, 180, 180, 180, 272, 272, 272, 272, 272, 272, 272, 272,\n",
      "        284, 284, 284, 284, 284, 284, 284, 284], dtype=torch.int32)\n",
      "tensor(0.0907, grad_fn=<MeanBackward0>)\n",
      "tensor([266, 266, 266, 266, 266, 266, 266, 266, 154, 154, 154, 154, 154, 154,\n",
      "        154, 154,  17,  17,  17,  17,  17,  17,  17,  17,  40,  40,  40,  40,\n",
      "         40,  40,  40,  40,  30,  30,  30,  30,  30,  30,  30,  30, 126, 126,\n",
      "        126, 126, 126, 126, 126, 126, 153, 153, 153, 153, 153, 153, 153, 153,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50], dtype=torch.int32)\n",
      "tensor(0.3464, grad_fn=<MeanBackward0>)\n",
      "tensor([233, 233, 233, 233, 233, 233, 233, 233, 224, 224, 224, 224, 224, 224,\n",
      "        224, 224,  71,  71,  71,  71,  71,  71,  71,  71, 230, 230, 230, 230,\n",
      "        230, 230, 230, 230, 122, 122, 122, 122, 122, 122, 122, 122, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25], dtype=torch.int32)\n",
      "tensor(0.3853, grad_fn=<MeanBackward0>)\n",
      "tensor([  4,   4,   4,   4,   4,   4,   4,   4, 130, 130, 130, 130, 130, 130,\n",
      "        130, 130, 267, 267, 267, 267, 267, 267, 267, 267,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,  45,  45,  45,  45,  45,  45,  45,  45, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118,  16,  16,  16,  16,  16,  16,  16,  16,\n",
      "         13,  13,  13,  13,  13,  13,  13,  13], dtype=torch.int32)\n",
      "tensor(0.8297, grad_fn=<MeanBackward0>)\n",
      "tensor([  0,   0,   0,   0,   0,   0,   0,   0, 284, 284, 284, 284, 284, 284,\n",
      "        284, 284,  44,  44,  44,  44,  44,  44,  44,  44,  85,  85,  85,  85,\n",
      "         85,  85,  85,  85, 128, 128, 128, 128, 128, 128, 128, 128, 233, 233,\n",
      "        233, 233, 233, 233, 233, 233,  83,  83,  83,  83,  83,  83,  83,  83,\n",
      "         59,  59,  59,  59,  59,  59,  59,  59], dtype=torch.int32)\n",
      "tensor(1.3788, grad_fn=<MeanBackward0>)\n",
      "tensor([ 27,  27,  27,  27,  27,  27,  27,  27, 161, 161, 161, 161, 161, 161,\n",
      "        161, 161, 179, 179, 179, 179, 179, 179, 179, 179, 188, 188, 188, 188,\n",
      "        188, 188, 188, 188, 258, 258, 258, 258, 258, 258, 258, 258, 265, 265,\n",
      "        265, 265, 265, 265, 265, 265, 230, 230, 230, 230, 230, 230, 230, 230,\n",
      "        227, 227, 227, 227, 227, 227, 227, 227], dtype=torch.int32)\n",
      "tensor(0.3065, grad_fn=<MeanBackward0>)\n",
      "tensor([190, 190, 190, 190, 190, 190, 190, 190, 210, 210, 210, 210, 210, 210,\n",
      "        210, 210, 265, 265, 265, 265, 265, 265, 265, 265, 266, 266, 266, 266,\n",
      "        266, 266, 266, 266,  49,  49,  49,  49,  49,  49,  49,  49, 249, 249,\n",
      "        249, 249, 249, 249, 249, 249, 181, 181, 181, 181, 181, 181, 181, 181,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133], dtype=torch.int32)\n",
      "tensor(0.7539, grad_fn=<MeanBackward0>)\n",
      "tensor([211, 211, 211, 211, 211, 211, 211, 211,  15,  15,  15,  15,  15,  15,\n",
      "         15,  15, 193, 193, 193, 193, 193, 193, 193, 193, 188, 188, 188, 188,\n",
      "        188, 188, 188, 188,  82,  82,  82,  82,  82,  82,  82,  82, 174, 174,\n",
      "        174, 174, 174, 174, 174, 174, 246, 246, 246, 246, 246, 246, 246, 246,\n",
      "         62,  62,  62,  62,  62,  62,  62,  62], dtype=torch.int32)\n",
      "tensor(0.7191, grad_fn=<MeanBackward0>)\n",
      "tensor([220, 220, 220, 220, 220, 220, 220, 220, 257, 257, 257, 257, 257, 257,\n",
      "        257, 257, 139, 139, 139, 139, 139, 139, 139, 139, 173, 173, 173, 173,\n",
      "        173, 173, 173, 173, 195, 195, 195, 195, 195, 195, 195, 195, 265, 265,\n",
      "        265, 265, 265, 265, 265, 265, 242, 242, 242, 242, 242, 242, 242, 242,\n",
      "         93,  93,  93,  93,  93,  93,  93,  93], dtype=torch.int32)\n",
      "tensor(0.3844, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([220, 220, 220, 220, 220, 220, 220, 220, 239, 239, 239, 239, 239, 239,\n",
      "        239, 239, 176, 176, 176, 176, 176, 176, 176, 176,  76,  76,  76,  76,\n",
      "         76,  76,  76,  76, 251, 251, 251, 251, 251, 251, 251, 251, 178, 178,\n",
      "        178, 178, 178, 178, 178, 178,  63,  63,  63,  63,  63,  63,  63,  63,\n",
      "        279, 279, 279, 279, 279, 279, 279, 279], dtype=torch.int32)\n",
      "tensor(0.5358, grad_fn=<MeanBackward0>)\n",
      "tensor([ 87,  87,  87,  87,  87,  87,  87,  87, 282, 282, 282, 282, 282, 282,\n",
      "        282, 282,   1,   1,   1,   1,   1,   1,   1,   1, 275, 275, 275, 275,\n",
      "        275, 275, 275, 275,   5,   5,   5,   5,   5,   5,   5,   5, 269, 269,\n",
      "        269, 269, 269, 269, 269, 269,  84,  84,  84,  84,  84,  84,  84,  84,\n",
      "        252, 252, 252, 252, 252, 252, 252, 252], dtype=torch.int32)\n",
      "tensor(0.6907, grad_fn=<MeanBackward0>)\n",
      "tensor([276, 276, 276, 276, 276, 276, 276, 276, 219, 219, 219, 219, 219, 219,\n",
      "        219, 219, 171, 171, 171, 171, 171, 171, 171, 171, 237, 237, 237, 237,\n",
      "        237, 237, 237, 237,  88,  88,  88,  88,  88,  88,  88,  88,  39,  39,\n",
      "         39,  39,  39,  39,  39,  39,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "        157, 157, 157, 157, 157, 157, 157, 157], dtype=torch.int32)\n",
      "tensor(0.3598, grad_fn=<MeanBackward0>)\n",
      "tensor([ 43,  43,  43,  43,  43,  43,  43,  43, 283, 283, 283, 283, 283, 283,\n",
      "        283, 283, 121, 121, 121, 121, 121, 121, 121, 121, 285, 285, 285, 285,\n",
      "        285, 285, 285, 285, 228, 228, 228, 228, 228, 228, 228, 228,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27, 237, 237, 237, 237, 237, 237, 237, 237,\n",
      "         84,  84,  84,  84,  84,  84,  84,  84], dtype=torch.int32)\n",
      "tensor(0.3474, grad_fn=<MeanBackward0>)\n",
      "tensor([235, 235, 235, 235, 235, 235, 235, 235, 263, 263, 263, 263, 263, 263,\n",
      "        263, 263, 171, 171, 171, 171, 171, 171, 171, 171, 245, 245, 245, 245,\n",
      "        245, 245, 245, 245, 262, 262, 262, 262, 262, 262, 262, 262,  80,  80,\n",
      "         80,  80,  80,  80,  80,  80,  45,  45,  45,  45,  45,  45,  45,  45,\n",
      "         47,  47,  47,  47,  47,  47,  47,  47], dtype=torch.int32)\n",
      "tensor(0.3119, grad_fn=<MeanBackward0>)\n",
      "tensor([ 74,  74,  74,  74,  74,  74,  74,  74,  82,  82,  82,  82,  82,  82,\n",
      "         82,  82, 288, 288, 288, 288, 288, 288, 288, 288,  80,  80,  80,  80,\n",
      "         80,  80,  80,  80,   2,   2,   2,   2,   2,   2,   2,   2, 158, 158,\n",
      "        158, 158, 158, 158, 158, 158, 109, 109, 109, 109, 109, 109, 109, 109,\n",
      "         63,  63,  63,  63,  63,  63,  63,  63], dtype=torch.int32)\n",
      "tensor(0.2620, grad_fn=<MeanBackward0>)\n",
      "tensor([ 79,  79,  79,  79,  79,  79,  79,  79, 145, 145, 145, 145, 145, 145,\n",
      "        145, 145, 137, 137, 137, 137, 137, 137, 137, 137, 238, 238, 238, 238,\n",
      "        238, 238, 238, 238, 101, 101, 101, 101, 101, 101, 101, 101,  74,  74,\n",
      "         74,  74,  74,  74,  74,  74, 131, 131, 131, 131, 131, 131, 131, 131,\n",
      "        167, 167, 167, 167, 167, 167, 167, 167], dtype=torch.int32)\n",
      "tensor(0.7446, grad_fn=<MeanBackward0>)\n",
      "tensor([173, 173, 173, 173, 173, 173, 173, 173, 108, 108, 108, 108, 108, 108,\n",
      "        108, 108, 251, 251, 251, 251, 251, 251, 251, 251,  75,  75,  75,  75,\n",
      "         75,  75,  75,  75,  16,  16,  16,  16,  16,  16,  16,  16, 272, 272,\n",
      "        272, 272, 272, 272, 272, 272, 281, 281, 281, 281, 281, 281, 281, 281,\n",
      "        132, 132, 132, 132, 132, 132, 132, 132], dtype=torch.int32)\n",
      "tensor(0.3335, grad_fn=<MeanBackward0>)\n",
      "tensor([  4,   4,   4,   4,   4,   4,   4,   4,  74,  74,  74,  74,  74,  74,\n",
      "         74,  74, 113, 113, 113, 113, 113, 113, 113, 113, 162, 162, 162, 162,\n",
      "        162, 162, 162, 162, 153, 153, 153, 153, 153, 153, 153, 153, 152, 152,\n",
      "        152, 152, 152, 152, 152, 152,  71,  71,  71,  71,  71,  71,  71,  71,\n",
      "        104, 104, 104, 104, 104, 104, 104, 104], dtype=torch.int32)\n",
      "tensor(0.2456, grad_fn=<MeanBackward0>)\n",
      "tensor([ 39,  39,  39,  39,  39,  39,  39,  39, 208, 208, 208, 208, 208, 208,\n",
      "        208, 208,  80,  80,  80,  80,  80,  80,  80,  80, 154, 154, 154, 154,\n",
      "        154, 154, 154, 154,  12,  12,  12,  12,  12,  12,  12,  12,  51,  51,\n",
      "         51,  51,  51,  51,  51,  51, 158, 158, 158, 158, 158, 158, 158, 158,\n",
      "        234, 234, 234, 234, 234, 234, 234, 234], dtype=torch.int32)\n",
      "tensor(0.3922, grad_fn=<MeanBackward0>)\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144, 119, 119, 119, 119, 119, 119,\n",
      "        119, 119,  64,  64,  64,  64,  64,  64,  64,  64,  12,  12,  12,  12,\n",
      "         12,  12,  12,  12, 280, 280, 280, 280, 280, 280, 280, 280, 263, 263,\n",
      "        263, 263, 263, 263, 263, 263, 135, 135, 135, 135, 135, 135, 135, 135,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122], dtype=torch.int32)\n",
      "tensor(0.7678, grad_fn=<MeanBackward0>)\n",
      "tensor([184, 184, 184, 184, 184, 184, 184, 184, 162, 162, 162, 162, 162, 162,\n",
      "        162, 162, 113, 113, 113, 113, 113, 113, 113, 113, 226, 226, 226, 226,\n",
      "        226, 226, 226, 226, 101, 101, 101, 101, 101, 101, 101, 101, 202, 202,\n",
      "        202, 202, 202, 202, 202, 202,  10,  10,  10,  10,  10,  10,  10,  10,\n",
      "        191, 191, 191, 191, 191, 191, 191, 191], dtype=torch.int32)\n",
      "tensor(0.3407, grad_fn=<MeanBackward0>)\n",
      "tensor([139, 139, 139, 139, 139, 139, 139, 139, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114, 169, 169, 169, 169, 169, 169, 169, 169, 194, 194, 194, 194,\n",
      "        194, 194, 194, 194, 280, 280, 280, 280, 280, 280, 280, 280, 157, 157,\n",
      "        157, 157, 157, 157, 157, 157, 259, 259, 259, 259, 259, 259, 259, 259,\n",
      "         98,  98,  98,  98,  98,  98,  98,  98], dtype=torch.int32)\n",
      "tensor(0.5844, grad_fn=<MeanBackward0>)\n",
      "tensor([ 37,  37,  37,  37,  37,  37,  37,  37, 137, 137, 137, 137, 137, 137,\n",
      "        137, 137,  16,  16,  16,  16,  16,  16,  16,  16, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140, 243, 243, 243, 243, 243, 243, 243, 243,  14,  14,\n",
      "         14,  14,  14,  14,  14,  14, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        180, 180, 180, 180, 180, 180, 180, 180], dtype=torch.int32)\n",
      "tensor(0.2824, grad_fn=<MeanBackward0>)\n",
      "tensor([ 41,  41,  41,  41,  41,  41,  41,  41, 199, 199, 199, 199, 199, 199,\n",
      "        199, 199, 159, 159, 159, 159, 159, 159, 159, 159, 123, 123, 123, 123,\n",
      "        123, 123, 123, 123, 218, 218, 218, 218, 218, 218, 218, 218,  15,  15,\n",
      "         15,  15,  15,  15,  15,  15,  39,  39,  39,  39,  39,  39,  39,  39,\n",
      "        104, 104, 104, 104, 104, 104, 104, 104], dtype=torch.int32)\n",
      "tensor(0.4141, grad_fn=<MeanBackward0>)\n",
      "tensor([ 87,  87,  87,  87,  87,  87,  87,  87, 258, 258, 258, 258, 258, 258,\n",
      "        258, 258,   9,   9,   9,   9,   9,   9,   9,   9, 126, 126, 126, 126,\n",
      "        126, 126, 126, 126, 163, 163, 163, 163, 163, 163, 163, 163,  22,  22,\n",
      "         22,  22,  22,  22,  22,  22, 212, 212, 212, 212, 212, 212, 212, 212,\n",
      "        274, 274, 274, 274, 274, 274, 274, 274], dtype=torch.int32)\n",
      "tensor(0.5224, grad_fn=<MeanBackward0>)\n",
      "tensor([ 22,  22,  22,  22,  22,  22,  22,  22, 259, 259, 259, 259, 259, 259,\n",
      "        259, 259,  44,  44,  44,  44,  44,  44,  44,  44, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 256, 256, 256, 256, 256, 256, 256, 256, 238, 238,\n",
      "        238, 238, 238, 238, 238, 238, 252, 252, 252, 252, 252, 252, 252, 252,\n",
      "        189, 189, 189, 189, 189, 189, 189, 189], dtype=torch.int32)\n",
      "tensor(0.3313, grad_fn=<MeanBackward0>)\n",
      "tensor([279, 279, 279, 279, 279, 279, 279, 279, 239, 239, 239, 239, 239, 239,\n",
      "        239, 239,  53,  53,  53,  53,  53,  53,  53,  53,  42,  42,  42,  42,\n",
      "         42,  42,  42,  42, 258, 258, 258, 258, 258, 258, 258, 258, 146, 146,\n",
      "        146, 146, 146, 146, 146, 146, 182, 182, 182, 182, 182, 182, 182, 182,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92], dtype=torch.int32)\n",
      "tensor(0.4929, grad_fn=<MeanBackward0>)\n",
      "tensor([117, 117, 117, 117, 117, 117, 117, 117,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68, 124, 124, 124, 124, 124, 124, 124, 124, 266, 266, 266, 266,\n",
      "        266, 266, 266, 266,  80,  80,  80,  80,  80,  80,  80,  80, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 170, 170, 170, 170, 170, 170, 170, 170,\n",
      "        257, 257, 257, 257, 257, 257, 257, 257], dtype=torch.int32)\n",
      "tensor(0.1269, grad_fn=<MeanBackward0>)\n",
      "tensor([263, 263, 263, 263, 263, 263, 263, 263, 106, 106, 106, 106, 106, 106,\n",
      "        106, 106, 135, 135, 135, 135, 135, 135, 135, 135, 229, 229, 229, 229,\n",
      "        229, 229, 229, 229, 205, 205, 205, 205, 205, 205, 205, 205,  88,  88,\n",
      "         88,  88,  88,  88,  88,  88, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        257, 257, 257, 257, 257, 257, 257, 257], dtype=torch.int32)\n",
      "tensor(0.1595, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([213, 213, 213, 213, 213, 213, 213, 213, 237, 237, 237, 237, 237, 237,\n",
      "        237, 237, 193, 193, 193, 193, 193, 193, 193, 193, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105, 207, 207, 207, 207, 207, 207, 207, 207, 281, 281,\n",
      "        281, 281, 281, 281, 281, 281, 254, 254, 254, 254, 254, 254, 254, 254,\n",
      "        158, 158, 158, 158, 158, 158, 158, 158], dtype=torch.int32)\n",
      "tensor(0.7917, grad_fn=<MeanBackward0>)\n",
      "tensor([128, 128, 128, 128, 128, 128, 128, 128,  66,  66,  66,  66,  66,  66,\n",
      "         66,  66, 237, 237, 237, 237, 237, 237, 237, 237, 279, 279, 279, 279,\n",
      "        279, 279, 279, 279, 275, 275, 275, 275, 275, 275, 275, 275,  41,  41,\n",
      "         41,  41,  41,  41,  41,  41, 191, 191, 191, 191, 191, 191, 191, 191,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125], dtype=torch.int32)\n",
      "tensor(0.4497, grad_fn=<MeanBackward0>)\n",
      "tensor([281, 281, 281, 281, 281, 281, 281, 281, 160, 160, 160, 160, 160, 160,\n",
      "        160, 160,  28,  28,  28,  28,  28,  28,  28,  28,   6,   6,   6,   6,\n",
      "          6,   6,   6,   6,  27,  27,  27,  27,  27,  27,  27,  27,  15,  15,\n",
      "         15,  15,  15,  15,  15,  15,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232], dtype=torch.int32)\n",
      "tensor(0.2538, grad_fn=<MeanBackward0>)\n",
      "tensor([ 33,  33,  33,  33,  33,  33,  33,  33,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  20,  20,  20,  20,  20,  20,  20,  20, 250, 250, 250, 250,\n",
      "        250, 250, 250, 250,  32,  32,  32,  32,  32,  32,  32,  32,  39,  39,\n",
      "         39,  39,  39,  39,  39,  39, 264, 264, 264, 264, 264, 264, 264, 264,\n",
      "         11,  11,  11,  11,  11,  11,  11,  11], dtype=torch.int32)\n",
      "tensor(1.1966, grad_fn=<MeanBackward0>)\n",
      "tensor([ 29,  29,  29,  29,  29,  29,  29,  29, 183, 183, 183, 183, 183, 183,\n",
      "        183, 183,  59,  59,  59,  59,  59,  59,  59,  59, 264, 264, 264, 264,\n",
      "        264, 264, 264, 264, 136, 136, 136, 136, 136, 136, 136, 136,  19,  19,\n",
      "         19,  19,  19,  19,  19,  19,  55,  55,  55,  55,  55,  55,  55,  55,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24], dtype=torch.int32)\n",
      "tensor(0.6530, grad_fn=<MeanBackward0>)\n",
      "tensor([224, 224, 224, 224, 224, 224, 224, 224, 230, 230, 230, 230, 230, 230,\n",
      "        230, 230,  31,  31,  31,  31,  31,  31,  31,  31, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 236, 236, 236, 236, 236, 236, 236, 236,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,  94,  94,  94,  94,  94,  94,  94,  94,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122], dtype=torch.int32)\n",
      "tensor(0.2873, grad_fn=<MeanBackward0>)\n",
      "tensor([ 95,  95,  95,  95,  95,  95,  95,  95, 219, 219, 219, 219, 219, 219,\n",
      "        219, 219,  91,  91,  91,  91,  91,  91,  91,  91, 283, 283, 283, 283,\n",
      "        283, 283, 283, 283, 244, 244, 244, 244, 244, 244, 244, 244,  22,  22,\n",
      "         22,  22,  22,  22,  22,  22, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "         25,  25,  25,  25,  25,  25,  25,  25], dtype=torch.int32)\n",
      "tensor(0.6416, grad_fn=<MeanBackward0>)\n",
      "tensor([145, 145, 145, 145, 145, 145, 145, 145, 162, 162, 162, 162, 162, 162,\n",
      "        162, 162,  32,  32,  32,  32,  32,  32,  32,  32, 288, 288, 288, 288,\n",
      "        288, 288, 288, 288,  91,  91,  91,  91,  91,  91,  91,  91, 287, 287,\n",
      "        287, 287, 287, 287, 287, 287, 290, 290, 290, 290, 290, 290, 290, 290,\n",
      "        140, 140, 140, 140, 140, 140, 140, 140], dtype=torch.int32)\n",
      "tensor(0.9611, grad_fn=<MeanBackward0>)\n",
      "tensor([266, 266, 266, 266, 266, 266, 266, 266, 175, 175, 175, 175, 175, 175,\n",
      "        175, 175, 284, 284, 284, 284, 284, 284, 284, 284, 153, 153, 153, 153,\n",
      "        153, 153, 153, 153,  59,  59,  59,  59,  59,  59,  59,  59,  89,  89,\n",
      "         89,  89,  89,  89,  89,  89,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "        230, 230, 230, 230, 230, 230, 230, 230], dtype=torch.int32)\n",
      "tensor(0.3072, grad_fn=<MeanBackward0>)\n",
      "tensor([113, 113, 113, 113, 113, 113, 113, 113, 238, 238, 238, 238, 238, 238,\n",
      "        238, 238, 221, 221, 221, 221, 221, 221, 221, 221, 207, 207, 207, 207,\n",
      "        207, 207, 207, 207,  47,  47,  47,  47,  47,  47,  47,  47,  18,  18,\n",
      "         18,  18,  18,  18,  18,  18, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "        130, 130, 130, 130, 130, 130, 130, 130], dtype=torch.int32)\n",
      "tensor(0.3354, grad_fn=<MeanBackward0>)\n",
      "tensor([115, 115, 115, 115, 115, 115, 115, 115, 126, 126, 126, 126, 126, 126,\n",
      "        126, 126, 203, 203, 203, 203, 203, 203, 203, 203, 165, 165, 165, 165,\n",
      "        165, 165, 165, 165,  76,  76,  76,  76,  76,  76,  76,  76,  21,  21,\n",
      "         21,  21,  21,  21,  21,  21,  80,  80,  80,  80,  80,  80,  80,  80,\n",
      "        246, 246, 246, 246, 246, 246, 246, 246], dtype=torch.int32)\n",
      "tensor(0.1797, grad_fn=<MeanBackward0>)\n",
      "tensor([249, 249, 249, 249, 249, 249, 249, 249, 184, 184, 184, 184, 184, 184,\n",
      "        184, 184, 277, 277, 277, 277, 277, 277, 277, 277, 238, 238, 238, 238,\n",
      "        238, 238, 238, 238, 140, 140, 140, 140, 140, 140, 140, 140, 276, 276,\n",
      "        276, 276, 276, 276, 276, 276, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "         69,  69,  69,  69,  69,  69,  69,  69], dtype=torch.int32)\n",
      "tensor(0.6751, grad_fn=<MeanBackward0>)\n",
      "tensor([173, 173, 173, 173, 173, 173, 173, 173,  69,  69,  69,  69,  69,  69,\n",
      "         69,  69, 118, 118, 118, 118, 118, 118, 118, 118,  10,  10,  10,  10,\n",
      "         10,  10,  10,  10, 221, 221, 221, 221, 221, 221, 221, 221, 161, 161,\n",
      "        161, 161, 161, 161, 161, 161,  93,  93,  93,  93,  93,  93,  93,  93,\n",
      "        272, 272, 272, 272, 272, 272, 272, 272], dtype=torch.int32)\n",
      "tensor(0.2484, grad_fn=<MeanBackward0>)\n",
      "tensor([  5,   5,   5,   5,   5,   5,   5,   5, 111, 111, 111, 111, 111, 111,\n",
      "        111, 111, 229, 229, 229, 229, 229, 229, 229, 229,  87,  87,  87,  87,\n",
      "         87,  87,  87,  87, 272, 272, 272, 272, 272, 272, 272, 272,   7,   7,\n",
      "          7,   7,   7,   7,   7,   7, 281, 281, 281, 281, 281, 281, 281, 281,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147], dtype=torch.int32)\n",
      "tensor(0.0971, grad_fn=<MeanBackward0>)\n",
      "tensor([141, 141, 141, 141, 141, 141, 141, 141, 153, 153, 153, 153, 153, 153,\n",
      "        153, 153,  25,  25,  25,  25,  25,  25,  25,  25, 191, 191, 191, 191,\n",
      "        191, 191, 191, 191, 262, 262, 262, 262, 262, 262, 262, 262,  16,  16,\n",
      "         16,  16,  16,  16,  16,  16, 223, 223, 223, 223, 223, 223, 223, 223,\n",
      "        285, 285, 285, 285, 285, 285, 285, 285], dtype=torch.int32)\n",
      "tensor(0.4745, grad_fn=<MeanBackward0>)\n",
      "tensor([145, 145, 145, 145, 145, 145, 145, 145, 182, 182, 182, 182, 182, 182,\n",
      "        182, 182,  61,  61,  61,  61,  61,  61,  61,  61, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 231, 231, 231, 231, 231, 231, 231, 231,   3,   3,\n",
      "          3,   3,   3,   3,   3,   3,  75,  75,  75,  75,  75,  75,  75,  75,\n",
      "        275, 275, 275, 275, 275, 275, 275, 275], dtype=torch.int32)\n",
      "tensor(0.4835, grad_fn=<MeanBackward0>)\n",
      "tensor([123, 123, 123, 123, 123, 123, 123, 123, 169, 169, 169, 169, 169, 169,\n",
      "        169, 169, 222, 222, 222, 222, 222, 222, 222, 222, 268, 268, 268, 268,\n",
      "        268, 268, 268, 268,  74,  74,  74,  74,  74,  74,  74,  74, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 163, 163, 163, 163, 163, 163, 163, 163,\n",
      "        180, 180, 180, 180, 180, 180, 180, 180], dtype=torch.int32)\n",
      "tensor(0.3117, grad_fn=<MeanBackward0>)\n",
      "tensor([110, 110, 110, 110, 110, 110, 110, 110, 241, 241, 241, 241, 241, 241,\n",
      "        241, 241,  39,  39,  39,  39,  39,  39,  39,  39, 273, 273, 273, 273,\n",
      "        273, 273, 273, 273,  17,  17,  17,  17,  17,  17,  17,  17, 170, 170,\n",
      "        170, 170, 170, 170, 170, 170, 178, 178, 178, 178, 178, 178, 178, 178,\n",
      "         99,  99,  99,  99,  99,  99,  99,  99], dtype=torch.int32)\n",
      "tensor(0.4339, grad_fn=<MeanBackward0>)\n",
      "tensor([259, 259, 259, 259, 259, 259, 259, 259, 210, 210, 210, 210, 210, 210,\n",
      "        210, 210,  13,  13,  13,  13,  13,  13,  13,  13,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  81,  81,  81,  81,  81,  81,  81,  81, 191, 191,\n",
      "        191, 191, 191, 191, 191, 191, 117, 117, 117, 117, 117, 117, 117, 117,\n",
      "        105, 105, 105, 105, 105, 105, 105, 105], dtype=torch.int32)\n",
      "tensor(0.4059, grad_fn=<MeanBackward0>)\n",
      "tensor([289, 289, 289, 289, 289, 289, 289, 289, 253, 253, 253, 253, 253, 253,\n",
      "        253, 253, 213, 213, 213, 213, 213, 213, 213, 213, 149, 149, 149, 149,\n",
      "        149, 149, 149, 149, 270, 270, 270, 270, 270, 270, 270, 270, 208, 208,\n",
      "        208, 208, 208, 208, 208, 208, 207, 207, 207, 207, 207, 207, 207, 207,\n",
      "        164, 164, 164, 164, 164, 164, 164, 164], dtype=torch.int32)\n",
      "tensor(0.8558, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([248, 248, 248, 248, 248, 248, 248, 248, 170, 170, 170, 170, 170, 170,\n",
      "        170, 170,  65,  65,  65,  65,  65,  65,  65,  65,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,   7,   7,   7,   7,   7,   7,   7,   7, 184, 184,\n",
      "        184, 184, 184, 184, 184, 184, 288, 288, 288, 288, 288, 288, 288, 288,\n",
      "        260, 260, 260, 260, 260, 260, 260, 260], dtype=torch.int32)\n",
      "tensor(0.1244, grad_fn=<MeanBackward0>)\n",
      "tensor([255, 255, 255, 255, 255, 255, 255, 255,   9,   9,   9,   9,   9,   9,\n",
      "          9,   9, 258, 258, 258, 258, 258, 258, 258, 258, 251, 251, 251, 251,\n",
      "        251, 251, 251, 251, 167, 167, 167, 167, 167, 167, 167, 167, 213, 213,\n",
      "        213, 213, 213, 213, 213, 213, 208, 208, 208, 208, 208, 208, 208, 208,\n",
      "         77,  77,  77,  77,  77,  77,  77,  77], dtype=torch.int32)\n",
      "tensor(0.7357, grad_fn=<MeanBackward0>)\n",
      "tensor([124, 124, 124, 124, 124, 124, 124, 124,  88,  88,  88,  88,  88,  88,\n",
      "         88,  88, 277, 277, 277, 277, 277, 277, 277, 277, 121, 121, 121, 121,\n",
      "        121, 121, 121, 121, 101, 101, 101, 101, 101, 101, 101, 101, 227, 227,\n",
      "        227, 227, 227, 227, 227, 227,   9,   9,   9,   9,   9,   9,   9,   9,\n",
      "        144, 144, 144, 144, 144, 144, 144, 144], dtype=torch.int32)\n",
      "tensor(0.6564, grad_fn=<MeanBackward0>)\n",
      "tensor([172, 172, 172, 172, 172, 172, 172, 172, 188, 188, 188, 188, 188, 188,\n",
      "        188, 188,  49,  49,  49,  49,  49,  49,  49,  49,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92, 180, 180, 180, 180, 180, 180, 180, 180,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38, 249, 249, 249, 249, 249, 249, 249, 249,\n",
      "        159, 159, 159, 159, 159, 159, 159, 159], dtype=torch.int32)\n",
      "tensor(0.1114, grad_fn=<MeanBackward0>)\n",
      "tensor([255, 255, 255, 255, 255, 255, 255, 255,  52,  52,  52,  52,  52,  52,\n",
      "         52,  52,  37,  37,  37,  37,  37,  37,  37,  37, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 168, 168, 168, 168, 168, 168, 168, 168,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91, 165, 165, 165, 165, 165, 165, 165, 165,\n",
      "        108, 108, 108, 108, 108, 108, 108, 108], dtype=torch.int32)\n",
      "tensor(0.5357, grad_fn=<MeanBackward0>)\n",
      "tensor([114, 114, 114, 114, 114, 114, 114, 114,  63,  63,  63,  63,  63,  63,\n",
      "         63,  63, 185, 185, 185, 185, 185, 185, 185, 185, 239, 239, 239, 239,\n",
      "        239, 239, 239, 239,  84,  84,  84,  84,  84,  84,  84,  84, 202, 202,\n",
      "        202, 202, 202, 202, 202, 202,  69,  69,  69,  69,  69,  69,  69,  69,\n",
      "        225, 225, 225, 225, 225, 225, 225, 225], dtype=torch.int32)\n",
      "tensor(0.9520, grad_fn=<MeanBackward0>)\n",
      "tensor([ 37,  37,  37,  37,  37,  37,  37,  37, 122, 122, 122, 122, 122, 122,\n",
      "        122, 122,  67,  67,  67,  67,  67,  67,  67,  67,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17, 114, 114, 114, 114, 114, 114, 114, 114, 234, 234,\n",
      "        234, 234, 234, 234, 234, 234,  87,  87,  87,  87,  87,  87,  87,  87,\n",
      "        226, 226, 226, 226, 226, 226, 226, 226], dtype=torch.int32)\n",
      "tensor(0.1396, grad_fn=<MeanBackward0>)\n",
      "tensor([120, 120, 120, 120, 120, 120, 120, 120, 252, 252, 252, 252, 252, 252,\n",
      "        252, 252, 165, 165, 165, 165, 165, 165, 165, 165,  52,  52,  52,  52,\n",
      "         52,  52,  52,  52, 242, 242, 242, 242, 242, 242, 242, 242, 237, 237,\n",
      "        237, 237, 237, 237, 237, 237, 272, 272, 272, 272, 272, 272, 272, 272,\n",
      "        286, 286, 286, 286, 286, 286, 286, 286], dtype=torch.int32)\n",
      "tensor(0.2117, grad_fn=<MeanBackward0>)\n",
      "tensor([155, 155, 155, 155, 155, 155, 155, 155,  23,  23,  23,  23,  23,  23,\n",
      "         23,  23, 200, 200, 200, 200, 200, 200, 200, 200, 236, 236, 236, 236,\n",
      "        236, 236, 236, 236,  93,  93,  93,  93,  93,  93,  93,  93, 123, 123,\n",
      "        123, 123, 123, 123, 123, 123,  36,  36,  36,  36,  36,  36,  36,  36,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118], dtype=torch.int32)\n",
      "tensor(0.1802, grad_fn=<MeanBackward0>)\n",
      "tensor([263, 263, 263, 263, 263, 263, 263, 263, 205, 205, 205, 205, 205, 205,\n",
      "        205, 205, 147, 147, 147, 147, 147, 147, 147, 147, 229, 229, 229, 229,\n",
      "        229, 229, 229, 229, 256, 256, 256, 256, 256, 256, 256, 256,  18,  18,\n",
      "         18,  18,  18,  18,  18,  18,  33,  33,  33,  33,  33,  33,  33,  33,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125], dtype=torch.int32)\n",
      "tensor(0.3229, grad_fn=<MeanBackward0>)\n",
      "tensor([269, 269, 269, 269, 269, 269, 269, 269, 275, 275, 275, 275, 275, 275,\n",
      "        275, 275,  53,  53,  53,  53,  53,  53,  53,  53,  98,  98,  98,  98,\n",
      "         98,  98,  98,  98, 226, 226, 226, 226, 226, 226, 226, 226, 125, 125,\n",
      "        125, 125, 125, 125, 125, 125, 239, 239, 239, 239, 239, 239, 239, 239,\n",
      "         33,  33,  33,  33,  33,  33,  33,  33], dtype=torch.int32)\n",
      "tensor(0.8327, grad_fn=<MeanBackward0>)\n",
      "tensor([207, 207, 207, 207, 207, 207, 207, 207, 218, 218, 218, 218, 218, 218,\n",
      "        218, 218, 135, 135, 135, 135, 135, 135, 135, 135, 198, 198, 198, 198,\n",
      "        198, 198, 198, 198, 272, 272, 272, 272, 272, 272, 272, 272, 254, 254,\n",
      "        254, 254, 254, 254, 254, 254,  84,  84,  84,  84,  84,  84,  84,  84,\n",
      "         67,  67,  67,  67,  67,  67,  67,  67], dtype=torch.int32)\n",
      "tensor(0.1364, grad_fn=<MeanBackward0>)\n",
      "tensor([ 39,  39,  39,  39,  39,  39,  39,  39, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 117, 117, 117, 117, 117, 117, 117, 117, 181, 181, 181, 181,\n",
      "        181, 181, 181, 181, 166, 166, 166, 166, 166, 166, 166, 166, 200, 200,\n",
      "        200, 200, 200, 200, 200, 200, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "         66,  66,  66,  66,  66,  66,  66,  66], dtype=torch.int32)\n",
      "tensor(0.1694, grad_fn=<MeanBackward0>)\n",
      "tensor([276, 276, 276, 276, 276, 276, 276, 276, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171,  86,  86,  86,  86,  86,  86,  86,  86, 163, 163, 163, 163,\n",
      "        163, 163, 163, 163, 115, 115, 115, 115, 115, 115, 115, 115,  99,  99,\n",
      "         99,  99,  99,  99,  99,  99, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149], dtype=torch.int32)\n",
      "tensor(0.4215, grad_fn=<MeanBackward0>)\n",
      "tensor([ 66,  66,  66,  66,  66,  66,  66,  66, 214, 214, 214, 214, 214, 214,\n",
      "        214, 214, 270, 270, 270, 270, 270, 270, 270, 270, 125, 125, 125, 125,\n",
      "        125, 125, 125, 125, 237, 237, 237, 237, 237, 237, 237, 237, 132, 132,\n",
      "        132, 132, 132, 132, 132, 132,  51,  51,  51,  51,  51,  51,  51,  51,\n",
      "        131, 131, 131, 131, 131, 131, 131, 131], dtype=torch.int32)\n",
      "tensor(0.4431, grad_fn=<MeanBackward0>)\n",
      "tensor([275, 275, 275, 275, 275, 275, 275, 275, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 252, 252, 252, 252, 252, 252, 252, 252,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   9,   9,   9,   9,   9,   9,   9,   9, 266, 266,\n",
      "        266, 266, 266, 266, 266, 266,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        238, 238, 238, 238, 238, 238, 238, 238], dtype=torch.int32)\n",
      "tensor(0.3172, grad_fn=<MeanBackward0>)\n",
      "tensor([ 97,  97,  97,  97,  97,  97,  97,  97, 211, 211, 211, 211, 211, 211,\n",
      "        211, 211,  39,  39,  39,  39,  39,  39,  39,  39, 249, 249, 249, 249,\n",
      "        249, 249, 249, 249, 142, 142, 142, 142, 142, 142, 142, 142, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247,  62,  62,  62,  62,  62,  62,  62,  62,\n",
      "         34,  34,  34,  34,  34,  34,  34,  34], dtype=torch.int32)\n",
      "tensor(0.2785, grad_fn=<MeanBackward0>)\n",
      "tensor([191, 191, 191, 191, 191, 191, 191, 191, 255, 255, 255, 255, 255, 255,\n",
      "        255, 255, 208, 208, 208, 208, 208, 208, 208, 208, 270, 270, 270, 270,\n",
      "        270, 270, 270, 270,  34,  34,  34,  34,  34,  34,  34,  34, 181, 181,\n",
      "        181, 181, 181, 181, 181, 181, 242, 242, 242, 242, 242, 242, 242, 242,\n",
      "        245, 245, 245, 245, 245, 245, 245, 245], dtype=torch.int32)\n",
      "tensor(0.8935, grad_fn=<MeanBackward0>)\n",
      "tensor([202, 202, 202, 202, 202, 202, 202, 202, 125, 125, 125, 125, 125, 125,\n",
      "        125, 125,  93,  93,  93,  93,  93,  93,  93,  93, 212, 212, 212, 212,\n",
      "        212, 212, 212, 212,  26,  26,  26,  26,  26,  26,  26,  26,  49,  49,\n",
      "         49,  49,  49,  49,  49,  49, 137, 137, 137, 137, 137, 137, 137, 137,\n",
      "         94,  94,  94,  94,  94,  94,  94,  94], dtype=torch.int32)\n",
      "tensor(0.4387, grad_fn=<MeanBackward0>)\n",
      "tensor([158, 158, 158, 158, 158, 158, 158, 158, 287, 287, 287, 287, 287, 287,\n",
      "        287, 287, 135, 135, 135, 135, 135, 135, 135, 135,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  25,  25,  25,  25,  25,  25,  25,  25, 258, 258,\n",
      "        258, 258, 258, 258, 258, 258,  70,  70,  70,  70,  70,  70,  70,  70,\n",
      "         63,  63,  63,  63,  63,  63,  63,  63], dtype=torch.int32)\n",
      "tensor(0.6065, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([104, 104, 104, 104, 104, 104, 104, 104,  33,  33,  33,  33,  33,  33,\n",
      "         33,  33,  53,  53,  53,  53,  53,  53,  53,  53, 184, 184, 184, 184,\n",
      "        184, 184, 184, 184, 142, 142, 142, 142, 142, 142, 142, 142, 267, 267,\n",
      "        267, 267, 267, 267, 267, 267,  11,  11,  11,  11,  11,  11,  11,  11,\n",
      "        228, 228, 228, 228, 228, 228, 228, 228], dtype=torch.int32)\n",
      "tensor(0.6691, grad_fn=<MeanBackward0>)\n",
      "tensor([129, 129, 129, 129, 129, 129, 129, 129,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99, 231, 231, 231, 231, 231, 231, 231, 231,  88,  88,  88,  88,\n",
      "         88,  88,  88,  88, 162, 162, 162, 162, 162, 162, 162, 162,  79,  79,\n",
      "         79,  79,  79,  79,  79,  79,  45,  45,  45,  45,  45,  45,  45,  45,\n",
      "        270, 270, 270, 270, 270, 270, 270, 270], dtype=torch.int32)\n",
      "tensor(0.2202, grad_fn=<MeanBackward0>)\n",
      "tensor([203, 203, 203, 203, 203, 203, 203, 203,  44,  44,  44,  44,  44,  44,\n",
      "         44,  44,  64,  64,  64,  64,  64,  64,  64,  64,  53,  53,  53,  53,\n",
      "         53,  53,  53,  53,  95,  95,  95,  95,  95,  95,  95,  95, 169, 169,\n",
      "        169, 169, 169, 169, 169, 169, 211, 211, 211, 211, 211, 211, 211, 211,\n",
      "         37,  37,  37,  37,  37,  37,  37,  37], dtype=torch.int32)\n",
      "tensor(0.5775, grad_fn=<MeanBackward0>)\n",
      "tensor([  9,   9,   9,   9,   9,   9,   9,   9,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  72,  72,  72,  72,  72,  72,  72,  72, 152, 152, 152, 152,\n",
      "        152, 152, 152, 152, 253, 253, 253, 253, 253, 253, 253, 253, 262, 262,\n",
      "        262, 262, 262, 262, 262, 262, 273, 273, 273, 273, 273, 273, 273, 273,\n",
      "        271, 271, 271, 271, 271, 271, 271, 271], dtype=torch.int32)\n",
      "tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "tensor([270, 270, 270, 270, 270, 270, 270, 270, 217, 217, 217, 217, 217, 217,\n",
      "        217, 217, 155, 155, 155, 155, 155, 155, 155, 155,  21,  21,  21,  21,\n",
      "         21,  21,  21,  21, 137, 137, 137, 137, 137, 137, 137, 137, 251, 251,\n",
      "        251, 251, 251, 251, 251, 251, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        259, 259, 259, 259, 259, 259, 259, 259], dtype=torch.int32)\n",
      "tensor(0.6076, grad_fn=<MeanBackward0>)\n",
      "tensor([101, 101, 101, 101, 101, 101, 101, 101, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114,  31,  31,  31,  31,  31,  31,  31,  31,  43,  43,  43,  43,\n",
      "         43,  43,  43,  43, 201, 201, 201, 201, 201, 201, 201, 201, 271, 271,\n",
      "        271, 271, 271, 271, 271, 271, 194, 194, 194, 194, 194, 194, 194, 194,\n",
      "          9,   9,   9,   9,   9,   9,   9,   9], dtype=torch.int32)\n",
      "tensor(0.0454, grad_fn=<MeanBackward0>)\n",
      "tensor([ 47,  47,  47,  47,  47,  47,  47,  47,  28,  28,  28,  28,  28,  28,\n",
      "         28,  28, 124, 124, 124, 124, 124, 124, 124, 124, 155, 155, 155, 155,\n",
      "        155, 155, 155, 155,  49,  49,  49,  49,  49,  49,  49,  49, 191, 191,\n",
      "        191, 191, 191, 191, 191, 191, 283, 283, 283, 283, 283, 283, 283, 283,\n",
      "        230, 230, 230, 230, 230, 230, 230, 230], dtype=torch.int32)\n",
      "tensor(0.2297, grad_fn=<MeanBackward0>)\n",
      "tensor([  5,   5,   5,   5,   5,   5,   5,   5, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 273, 273, 273, 273, 273, 273, 273, 273,  66,  66,  66,  66,\n",
      "         66,  66,  66,  66, 270, 270, 270, 270, 270, 270, 270, 270, 269, 269,\n",
      "        269, 269, 269, 269, 269, 269,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "        164, 164, 164, 164, 164, 164, 164, 164], dtype=torch.int32)\n",
      "tensor(0.6558, grad_fn=<MeanBackward0>)\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144,  77,  77,  77,  77,  77,  77,\n",
      "         77,  77, 230, 230, 230, 230, 230, 230, 230, 230, 218, 218, 218, 218,\n",
      "        218, 218, 218, 218, 198, 198, 198, 198, 198, 198, 198, 198, 169, 169,\n",
      "        169, 169, 169, 169, 169, 169,  94,  94,  94,  94,  94,  94,  94,  94,\n",
      "         28,  28,  28,  28,  28,  28,  28,  28], dtype=torch.int32)\n",
      "tensor(0.1190, grad_fn=<MeanBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d3671e5ccfba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelInter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'questions'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mquestions\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'generated_ques'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerated_ques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'bs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m64\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_save_path\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoints'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'myModel4'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\scripts\\modelInterface.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, model_save_path)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         )\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\cluster-model\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, fp16, fp16_opt_level, local_rank)\u001b[0m\n\u001b[0;32m    392\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelInter.train({'questions':questions , 'generated_ques': generated_ques, 'labels':labels , 'bs':64 ,'n':8},model_save_path =os.path.join('checkpoints', 'myModel4') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data_questions_labels_dict': data_questions_label_dict , 'test_questions_labels_dict' : test_questions_labels_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153846153846154"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInter.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeds = model.encode(questions)\n",
    "q_embeds = np.array(q_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq_embeds = model.encode(test_questions)\n",
    "tq_embeds = np.array(tq_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign():\n",
    "    n1 = np.linalg.norm(tq_embeds, axis = -1)\n",
    "    n2 = np.linalg.norm(q_embeds, axis = -1)\n",
    "    dot = np.expand_dims(tq_embeds , 1)*np.expand_dims(q_embeds,0)\n",
    "    dot = dot.sum(axis = -1)\n",
    "    ans = dot/n1.reshape(-1,1)\n",
    "    ans = ans/n2.reshape(1,-1)\n",
    "    return np.argmax(ans , axis = -1), ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned, ans = assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78735375, 0.91230446, 0.753919  , 0.7258304 , 0.927165  ,\n",
       "       0.88282144, 0.7784794 , 0.8124629 , 0.7006926 , 0.82574904,\n",
       "       0.7039604 , 0.7765373 , 0.76268244, 0.95239997, 0.87162924,\n",
       "       0.8413708 , 0.67673886, 0.81089014, 0.88396907, 0.73399264,\n",
       "       0.89649147, 0.9287177 , 0.5353112 , 0.84976786, 0.7745759 ,\n",
       "       0.7890316 , 0.9600214 , 0.8691442 , 0.92594224, 0.618693  ,\n",
       "       0.62028974, 0.9433868 , 0.9246678 , 0.7870786 , 0.70038885,\n",
       "       0.82204586, 0.6064853 , 0.8051151 , 0.9084486 , 0.8684028 ,\n",
       "       0.894618  , 0.91790235, 0.85900104, 0.93909425, 0.83968264,\n",
       "       0.9285271 , 0.8024838 , 0.9415216 , 0.9591521 , 0.5772507 ,\n",
       "       0.9115484 , 0.87189823, 0.9377835 , 0.82952034, 0.8774469 ,\n",
       "       0.9378167 , 0.8123381 , 0.717871  , 0.96868825, 0.9235323 ,\n",
       "       0.85285187, 0.9478283 , 0.8404879 , 0.9742791 , 0.92760664,\n",
       "       0.9801053 , 0.97454864, 0.93405783, 0.8453288 , 0.7521198 ,\n",
       "       0.86125225, 0.8883487 , 0.9417546 , 0.758313  , 0.934008  ,\n",
       "       0.9236708 , 0.9189825 , 0.94742745, 0.9629319 , 0.84534574,\n",
       "       0.769981  , 0.9338387 , 0.94608206, 0.9029584 , 0.8328997 ,\n",
       "       0.95469975, 0.91487575, 0.88750046, 0.9135992 , 0.8571373 ,\n",
       "       0.94827765, 0.9246306 , 0.81133986, 0.8110406 , 0.92573327,\n",
       "       0.9253352 , 0.92812324, 0.9474383 , 0.9416302 , 0.85518163,\n",
       "       0.8417295 , 0.7267629 , 0.6400673 , 0.86788017, 0.6826208 ,\n",
       "       0.5783895 , 0.7202238 , 0.84775877, 0.54805243, 0.8880069 ,\n",
       "       0.8331388 , 0.8187399 , 0.9020683 , 0.86628175, 0.7460359 ,\n",
       "       0.7327923 , 0.8864868 , 0.85834455, 0.92321056, 0.84940046,\n",
       "       0.44422072, 0.7325304 , 0.49995255, 0.6961615 , 0.33981615,\n",
       "       0.7700047 , 0.7061469 , 0.79019576, 0.36358422, 0.43258047],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.max(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 127, 226, 176,  98, 178, 234,  48, 167,  59, 176, 290, 292,\n",
       "         6,  62, 115, 104, 180, 196,  76, 230, 266, 130, 179, 186,  61,\n",
       "       208, 288, 235, 257, 183,  96,  83,  46,  27,   8,  95,  99,  71,\n",
       "        31,  15, 124, 169, 171, 264, 205, 276, 204, 284,   5, 124,   6,\n",
       "         8,  12,  18,  20,  21,  25,  30,  32,  42,  44,  48,  47,  49,\n",
       "        50,  57,  60,  62,  68,  44,  73,  76,  72,  83,  84,  87,  89,\n",
       "        88,  88,  92,  93,  96,  97, 100, 101, 102,  29, 114, 118, 119,\n",
       "       121, 123, 114, 126,  70, 132, 136, 138, 141,   5,  96,  27,  62,\n",
       "        84, 203, 182, 222, 257, 286, 127, 123, 134, 141, 290, 187, 100,\n",
       "        51,  59, 130, 240, 265,  34, 290,  84, 115, 137,  60, 104,  52],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 127, 226, 176,  98, 178, 234,  48, 167,  59, 176, 290, 292,\n",
       "         6,  62, 115, 104, 180, 196,  76, 230, 266, 130, 179, 186,  61,\n",
       "       208, 288, 235, 257, 183,  96,  83,  46,  27,   8,  95,  99,  71,\n",
       "        31,  15, 124, 169, 171, 264, 205, 276, 204, 284,   5, 124,   6,\n",
       "         8,  12,  18,  20,  21,  25,  30,  32,  42,  44,  48,  47,  49,\n",
       "        50,  57,  60,  62,  68,  44,  73,  76,  72,  83,  84,  87,  89,\n",
       "        88,  88,  92,  93,  96,  97, 100, 101, 102,  29, 114, 118, 119,\n",
       "       121, 123, 114, 126,  70, 132, 136, 138, 141,   5,  96,  27,  62,\n",
       "        84, 203, 182, 222, 257, 286, 127, 123, 134, 141, 290, 187, 100,\n",
       "        51,  59, 130, 240, 265,  34, 290,  84, 115, 137,  60, 104,  52],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tars = np.array(test_answers).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.15384615384615"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((tars == assigned).sum()/130)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "\n",
    "\n",
    "class InputExample:\n",
    "    \"\"\"\n",
    "    Structure for one input example with texts, the label and a unique id\n",
    "    \"\"\"\n",
    "    def __init__(self, guid: str, texts: List[str], label: Union[int, float]):\n",
    "        \"\"\"\n",
    "        Creates one InputExample with the given texts, guid and label\n",
    "        str.strip() is called on both texts.\n",
    "        :param guid\n",
    "            id for the example\n",
    "        :param texts\n",
    "            the texts for the example\n",
    "        :param label\n",
    "            the label for the example\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.texts = [text.strip() for text in texts]\n",
    "        self.label = label\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<InputExample> label: {}, texts: {}\".format(str(self.label), \"; \".join(self.texts))\n",
    "\n",
    "\n",
    "class Question_sampler(Dataset): \n",
    "    def __init__(self,questions,generated_ques,model,labels = None, bs = 32 , n = 4):\n",
    "        \"\"\"\n",
    "        questions --> array of string\n",
    "        labels --> array of labels\n",
    "        generated_ques --> a dict from ques to array of generated ques\n",
    "        bs --> batch size\n",
    "        n  --> number of classes to pick , from \n",
    "        \"\"\"\n",
    "       \n",
    "        self.questions = questions\n",
    "        if(labels is None):\n",
    "            labels = [x for x in range(len(questions))]\n",
    "            \n",
    "        assert len(questions) == len(labels), 'length of ques is {} but len of labels is {}'.format(len(questions), len(labels))\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.model = model\n",
    "        self.data = {}\n",
    "        # data is a dict from label to array of questions\n",
    "        self.min_gen = 100000000000\n",
    "        self.classes = len(set(self.labels))\n",
    "        for i,que in enumerate(questions):\n",
    "            self.min_gen = min(self.min_gen , len(generated_ques[que]))\n",
    "            if(self.labels[i] not in self.data):\n",
    "                self.data[self.labels[i]] = []\n",
    "            self.data[self.labels[i]] += [que] + generated_ques[que]\n",
    "             \n",
    "        self.sequence = []\n",
    "        self.make_sequence(total_examples = len(questions)*3, batch_size = bs,n = n)\n",
    "    def __len__(self):\n",
    "        return len(self.sequence[0])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inp , lab = self.sequence\n",
    "        return [inp[index]], lab[index]\n",
    "    def sample_triplet(self):\n",
    "        \"\"\"\n",
    "        To sample triplet from a sentence\n",
    "        returns a pair of triplet\n",
    "        [Anchor , positive , negative]\n",
    "        \"\"\"\n",
    "        total_ques = len(self.questions)\n",
    "        anchor_data_index,neg_data_index = np.random.choice(len(self.data), size = 2,replace = False).tolist()\n",
    "        pos_list = self.data[anchor_data_index]\n",
    "        anchor_index , pos_index = np.random.choice(len(pos_list), size = 2,replace = False).tolist()\n",
    "        anchor , pos = pos_list[anchor_index].strip() , pos_list[pos_index].strip() \n",
    "        neg_list = self.data[neg_data_index]\n",
    "        neg_index = np.random.choice(len(neg_list))\n",
    "        neg = neg_list[neg_index]\n",
    "        \n",
    "        \n",
    "        return [anchor, pos, neg]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def make_sequence_util(self, n , k):\n",
    "        \"\"\"\n",
    "        to make a batch of n classes\n",
    "        where each class has k examples\n",
    "        \"\"\"\n",
    "        if(n <= self.classes):\n",
    "            class_indices = np.random.choice(self.labels , size = n , replace = False)\n",
    "        else:\n",
    "            warnings.warn('n is greater than number of classes') \n",
    "            class_indices = np.random.choice(self.labels , size = n , replace = True)\n",
    "        \n",
    "        \n",
    "        batch_inps = []\n",
    "        batch_labels = []\n",
    "        for i in class_indices:\n",
    "            label = i\n",
    "            ques = self.data[i]\n",
    "            num_ques = len(ques)\n",
    "            if(k <= num_ques):\n",
    "                que_indices = np.random.choice(num_ques, size = k, replace = False)\n",
    "            else:\n",
    "                warnings.warn('k is greater than than number of generated ques')\n",
    "                que_indices = np.random.choice(num_ques, size = k, replace = True)\n",
    "                \n",
    "            for j in que_indices:\n",
    "                batch_inps.append(self.model.tokenize(ques[j]))\n",
    "                batch_labels.append(label)\n",
    "        return [batch_inps, batch_labels]\n",
    "            \n",
    "    def make_sequence(self,total_examples,batch_size,n):\n",
    "        \"\"\"\n",
    "        total_examples number of batches are formed --> making the seq batch_size*total_examples long\n",
    "        n  class are drawn in each batch \n",
    "        batch_size//n number of examples for each classes\n",
    "        \"\"\"\n",
    "        assert batch_size%n == 0 , 'batch_size should be divisible by n'\n",
    "        self.sequence = []\n",
    "        batch_inps = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for i in range(total_examples):\n",
    "            x,y = self.make_sequence_util(n,batch_size//n)\n",
    "            # sampled a batch , of size batch_size\n",
    "            batch_inps += x\n",
    "            batch_labels += y\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.sequence = [batch_inps, torch.tensor(batch_labels)]\n",
    "        \n",
    "        \n",
    "def get_dataloader(self,questions,generated_ques,model,labels = None, bs = 32 , n = 4):\n",
    "    \"\"\"\n",
    "        questions --> array of string\n",
    "        labels --> array of labels\n",
    "        generated_ques --> a dict from ques to array of generated ques\n",
    "        bs --> batch size\n",
    "        n  --> number of classes to pick , from \n",
    "    \"\"\"\n",
    "\n",
    "    Q = Question_sampler(questions ,generated_ques,model,labels)\n",
    "    train_data = Q\n",
    "    train_dataloader = DataLoader(train_data,  batch_size= 32, sampler= SequentialSampler(train_data))\n",
    "    return train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.datasets import SentenceLabelDataset\n",
    "from sentence_transformers.data_samplers import LabelSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = Question_sampler(questions ,generated_ques,modelInter.model,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[118,\n",
       "   33,\n",
       "   682,\n",
       "   4813,\n",
       "   10,\n",
       "   2069,\n",
       "   13,\n",
       "   464,\n",
       "   9,\n",
       "   920,\n",
       "   709,\n",
       "   15756,\n",
       "   740,\n",
       "   6106,\n",
       "   19467,\n",
       "   804,\n",
       "   141,\n",
       "   109,\n",
       "   939,\n",
       "   216,\n",
       "   5,\n",
       "   1881,\n",
       "   9,\n",
       "   5,\n",
       "   464]],\n",
       " tensor(192, dtype=torch.int32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_data = Q\n",
    "train_dataloader = DataLoader(train_data,  batch_size= 32, sampler= SequentialSampler(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([192, 192, 192, 192, 192, 192, 192, 192, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 290, 290, 290, 290, 290, 290, 290, 290, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    _, label = data\n",
    "    print(label)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluator = TripletEvaluator(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.BatchHardTripletLoss(sentence_embedder=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_save_path = 'output/training_stsbenchmark_continue_training-'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_save_path = 'models/myModel3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391a20fd3326412db278bf037a1070ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca45f18ffa14bffb39310939c977df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1758.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([166, 166, 166, 166,  97,  97,  97,  97, 186, 186, 186, 186, 228, 228,\n",
      "        228, 228])\n",
      "tensor(0.0157, grad_fn=<MeanBackward0>)\n",
      "tensor([ 19,  19,  19,  19, 256, 256, 256, 256, 226, 226, 226, 226, 273, 273,\n",
      "        273, 273])\n",
      "tensor(0.0072, grad_fn=<MeanBackward0>)\n",
      "tensor([286, 286, 286, 286, 262, 262, 262, 262,  41,  41,  41,  41, 279, 279,\n",
      "        279, 279])\n",
      "tensor(0.0026, grad_fn=<MeanBackward0>)\n",
      "tensor([188, 188, 188, 188, 197, 197, 197, 197, 252, 252, 252, 252, 127, 127,\n",
      "        127, 127])\n",
      "tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "tensor([271, 271, 271, 271, 115, 115, 115, 115, 171, 171, 171, 171, 102, 102,\n",
      "        102, 102])\n",
      "tensor(9.3992e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([118, 118, 118, 118, 117, 117, 117, 117, 166, 166, 166, 166,  58,  58,\n",
      "         58,  58])\n",
      "tensor(0.6323, grad_fn=<MeanBackward0>)\n",
      "tensor([239, 239, 239, 239,  45,  45,  45,  45,  28,  28,  28,  28,  18,  18,\n",
      "         18,  18])\n",
      "tensor(0.0188, grad_fn=<MeanBackward0>)\n",
      "tensor([225, 225, 225, 225, 199, 199, 199, 199, 129, 129, 129, 129, 228, 228,\n",
      "        228, 228])\n",
      "tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "tensor([100, 100, 100, 100, 236, 236, 236, 236, 252, 252, 252, 252, 240, 240,\n",
      "        240, 240])\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([  5,   5,   5,   5, 220, 220, 220, 220,  16,  16,  16,  16,  48,  48,\n",
      "         48,  48])\n",
      "tensor(0.0308, grad_fn=<MeanBackward0>)\n",
      "tensor([ 68,  68,  68,  68,   8,   8,   8,   8, 263, 263, 263, 263, 276, 276,\n",
      "        276, 276])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([117, 117, 117, 117, 147, 147, 147, 147,  39,  39,  39,  39, 186, 186,\n",
      "        186, 186])\n",
      "tensor(6.9730e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([ 24,  24,  24,  24, 282, 282, 282, 282,  15,  15,  15,  15, 240, 240,\n",
      "        240, 240])\n",
      "tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "tensor([258, 258, 258, 258,  61,  61,  61,  61, 229, 229, 229, 229, 280, 280,\n",
      "        280, 280])\n",
      "tensor(8.4536e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([126, 126, 126, 126,  65,  65,  65,  65, 204, 204, 204, 204, 286, 286,\n",
      "        286, 286])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 66,  66,  66,  66, 229, 229, 229, 229,  56,  56,  56,  56, 131, 131,\n",
      "        131, 131])\n",
      "tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([215, 215, 215, 215, 226, 226, 226, 226,   6,   6,   6,   6, 136, 136,\n",
      "        136, 136])\n",
      "tensor(0.0141, grad_fn=<MeanBackward0>)\n",
      "tensor([259, 259, 259, 259, 251, 251, 251, 251,  76,  76,  76,  76, 121, 121,\n",
      "        121, 121])\n",
      "tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([290, 290, 290, 290,  70,  70,  70,  70, 228, 228, 228, 228, 181, 181,\n",
      "        181, 181])\n",
      "tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "tensor([ 56,  56,  56,  56, 144, 144, 144, 144, 215, 215, 215, 215,  90,  90,\n",
      "         90,  90])\n",
      "tensor(3.8179e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([162, 162, 162, 162, 289, 289, 289, 289, 233, 233, 233, 233,  81,  81,\n",
      "         81,  81])\n",
      "tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([202, 202, 202, 202,  46,  46,  46,  46, 210, 210, 210, 210, 277, 277,\n",
      "        277, 277])\n",
      "tensor(0.0376, grad_fn=<MeanBackward0>)\n",
      "tensor([204, 204, 204, 204,  29,  29,  29,  29,  85,  85,  85,  85,  67,  67,\n",
      "         67,  67])\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([ 64,  64,  64,  64, 223, 223, 223, 223, 149, 149, 149, 149, 136, 136,\n",
      "        136, 136])\n",
      "tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([185, 185, 185, 185,  71,  71,  71,  71, 223, 223, 223, 223, 121, 121,\n",
      "        121, 121])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 88,  88,  88,  88,  50,  50,  50,  50,  62,  62,  62,  62, 202, 202,\n",
      "        202, 202])\n",
      "tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([170, 170, 170, 170,  71,  71,  71,  71, 242, 242, 242, 242,  60,  60,\n",
      "         60,  60])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 86,  86,  86,  86,  91,  91,  91,  91, 168, 168, 168, 168, 241, 241,\n",
      "        241, 241])\n",
      "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
      "tensor([189, 189, 189, 189, 144, 144, 144, 144,  83,  83,  83,  83, 236, 236,\n",
      "        236, 236])\n",
      "tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "tensor([158, 158, 158, 158, 247, 247, 247, 247, 163, 163, 163, 163, 258, 258,\n",
      "        258, 258])\n",
      "tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([157, 157, 157, 157, 156, 156, 156, 156,   7,   7,   7,   7, 276, 276,\n",
      "        276, 276])\n",
      "tensor(4.2438e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([ 14,  14,  14,  14, 173, 173, 173, 173, 154, 154, 154, 154, 179, 179,\n",
      "        179, 179])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 22,  22,  22,  22,  45,  45,  45,  45,  92,  92,  92,  92, 254, 254,\n",
      "        254, 254])\n",
      "tensor(0.0073, grad_fn=<MeanBackward0>)\n",
      "tensor([238, 238, 238, 238, 174, 174, 174, 174, 266, 266, 266, 266, 202, 202,\n",
      "        202, 202])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 33,  33,  33,  33,  59,  59,  59,  59, 247, 247, 247, 247, 238, 238,\n",
      "        238, 238])\n",
      "tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "tensor([ 90,  90,  90,  90, 176, 176, 176, 176,  85,  85,  85,  85,  84,  84,\n",
      "         84,  84])\n",
      "tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "tensor([275, 275, 275, 275,  49,  49,  49,  49,  83,  83,  83,  83,  42,  42,\n",
      "         42,  42])\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([ 39,  39,  39,  39, 255, 255, 255, 255, 134, 134, 134, 134, 272, 272,\n",
      "        272, 272])\n",
      "tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "tensor([249, 249, 249, 249, 140, 140, 140, 140, 283, 283, 283, 283, 155, 155,\n",
      "        155, 155])\n",
      "tensor(7.3732e-05, grad_fn=<MeanBackward0>)\n",
      "tensor([151, 151, 151, 151, 146, 146, 146, 146, 255, 255, 255, 255, 185, 185,\n",
      "        185, 185])\n",
      "tensor(0.0134, grad_fn=<MeanBackward0>)\n",
      "tensor([ 92,  92,  92,  92,  39,  39,  39,  39, 169, 169, 169, 169, 211, 211,\n",
      "        211, 211])\n",
      "tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "tensor([ 77,  77,  77,  77, 267, 267, 267, 267, 159, 159, 159, 159,  32,  32,\n",
      "         32,  32])\n",
      "tensor(2.0295e-05, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    evaluator = None,\n",
    "    output_path= model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/myModel3\\\\modules.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-50598dbdc233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NTU_thesis\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[0;32m     73\u001b[0m                             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__version__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'modules.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfIn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m                     \u001b[0mcontained_modules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfIn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/myModel3\\\\modules.json'"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/myModel2'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.flow as naf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1 = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rjkin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "aug2 = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regx = re.compile(r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug3 = naw.SplitAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_num = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "que = re.sub(r'[^a-zA-Z0-9_ ]', '', questions[que_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have submitted request to open CDA Why is my status still at Inprogress'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have submitted r equest to op en CDA Why is my st atus sti ll at Inprogress'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug3.augment(que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 have submitted request to open up CDA Why be my position still at Inprogress',\n",
       " 'I have submitted petition to spread out CDA Why is my condition still at Inprogress',\n",
       " 'I have reconcile request to open up CDA Why is my condition still at Inprogress',\n",
       " 'I experience submitted request to open CDA Why is my position even so at Inprogress',\n",
       " 'I get submitted request to open CDA Why is my condition still at Inprogress']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug2.augment(que, n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i have submitted it to open cd . why is the contract now at inprogress',\n",
       " 'i also submitted critique of open cda why is the status still at ?',\n",
       " 'we have a request for open cda and is my status still a inprogress',\n",
       " 'i had submitted request to open again . is my status still at in ?',\n",
       " 'i then submitted request to start cd storage and has my status still at inprogress']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug1.augment(que, n =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i have submitted request to open cda why is status still at in progress',\n",
       " 'i have submitted request to accept open cda why is my status still at in progress',\n",
       " 'i have submitted request to my cda why is open status still at in progress',\n",
       " 'i submitted request to open cda why is my status still at progress',\n",
       " 'i have submitted request to open cda why is my status still at in shape up',\n",
       " 'i have submitted request to open cda why is silence my status still at in progress',\n",
       " 'i have submitted request to open cda why is my status still at in progress',\n",
       " 'i have submitted progress to open cda why is my status still at in request',\n",
       " 'i still submitted request to open cda why is my status have at in progress',\n",
       " 'i have submitted request to open cda why is my status still at in progress ']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ques[questions[que_num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = 0\n",
    "total = 0\n",
    "\n",
    "for q,qs in generated_ques.items():\n",
    "    total += len(qs)\n",
    "    unique += len(set(qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2842"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
